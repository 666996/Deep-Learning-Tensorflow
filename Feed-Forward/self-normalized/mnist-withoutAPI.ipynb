{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train-images-idx3-ubyte.gz\n",
      "Extracting train-labels-idx1-ubyte.gz\n",
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('', validation_size = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(x):\n",
    "    alpha = 1.6732632423543772848170429916717\n",
    "    scale = 1.0507009873554804934193349852946\n",
    "    return scale*tf.where(x>=0.0, x, alpha*tf.nn.elu(x))\n",
    "\n",
    "def alpha_dropout(x, rate, alpha=-1.7580993408473766, mean=0.0, var=1.0):\n",
    "    keep_prob = 1.0 - rate\n",
    "    random_tensor = tf.random_uniform(tf.shape(x)) + keep_prob\n",
    "    binary_tensor = tf.floor(random_tensor)\n",
    "    ret = x * binary_tensor + alpha * (1-binary_tensor)\n",
    "    a = tf.sqrt(var / (keep_prob *((1-keep_prob) * tf.pow(alpha-mean,2) + var)))\n",
    "    b = mean - a * (keep_prob * mean + (1 - keep_prob) * alpha)\n",
    "    return a * ret + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "        self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "        w1 = tf.Variable(tf.random_normal([784, 256], stddev=np.sqrt(1/784)))\n",
    "        b1 = tf.Variable(tf.random_normal([256],stddev=0))\n",
    "        w2 = tf.Variable(tf.random_normal([256, 100], stddev=np.sqrt(1/256)))\n",
    "        b2 = tf.Variable(tf.random_normal([100],stddev=0))\n",
    "        w3 = tf.Variable(tf.random_normal([100, 10], stddev=np.sqrt(1/100)))\n",
    "        b3 = tf.Variable(tf.random_normal([10],stddev=0))\n",
    "        feedforward = selu(tf.matmul(self.X, w1) + b1)\n",
    "        feeddropout = alpha_dropout(feedforward,0.5)\n",
    "        feedforward = selu(tf.matmul(feeddropout, w2) + b2)\n",
    "        feeddropout = alpha_dropout(feedforward,0.5)\n",
    "        self.logits = tf.matmul(feeddropout, w3) + b3\n",
    "        self.cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = self.Y, logits = self.logits))\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(self.cost)\n",
    "        correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epoch = 10\n",
    "\n",
    "train_images = (mnist.train.images - np.mean(mnist.train.images)) / np.std(mnist.train.images)\n",
    "test_images = (mnist.test.images - np.mean(mnist.test.images)) / np.std(mnist.test.images)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, accuracy train: 0.190288, accuracy testing: 0.284598\n",
      "epoch: 2, accuracy train: 0.384899, accuracy testing: 0.447545\n",
      "epoch: 3, accuracy train: 0.507595, accuracy testing: 0.517857\n",
      "epoch: 4, accuracy train: 0.581230, accuracy testing: 0.588170\n",
      "epoch: 5, accuracy train: 0.623965, accuracy testing: 0.648438\n",
      "epoch: 6, accuracy train: 0.658220, accuracy testing: 0.650670\n",
      "epoch: 7, accuracy train: 0.685580, accuracy testing: 0.679688\n",
      "epoch: 8, accuracy train: 0.706414, accuracy testing: 0.700893\n",
      "epoch: 9, accuracy train: 0.724426, accuracy testing: 0.700893\n",
      "epoch: 10, accuracy train: 0.738548, accuracy testing: 0.736607\n"
     ]
    }
   ],
   "source": [
    "LOSS, ACC_TRAIN, ACC_TEST = [], [], []\n",
    "for i in range(epoch):\n",
    "    total_loss, total_acc = 0, 0\n",
    "    for n in range(0, (mnist.train.images.shape[0] // batch_size) * batch_size, batch_size):\n",
    "        batch_x = train_images[n: n + batch_size, :]\n",
    "        batch_y = np.zeros((batch_size, 10))\n",
    "        batch_y[np.arange(batch_size),mnist.train.labels[n:n+batch_size]] = 1.0\n",
    "        cost, _ = sess.run([model.cost, model.optimizer], \n",
    "                           feed_dict = {model.X : batch_x, \n",
    "                                        model.Y : batch_y})\n",
    "        total_acc += sess.run(model.accuracy, \n",
    "                              feed_dict = {model.X : batch_x, \n",
    "                                           model.Y : batch_y})\n",
    "        total_loss += cost\n",
    "    total_loss /= (mnist.train.images.shape[0] // batch_size)\n",
    "    total_acc /= (mnist.train.images.shape[0] // batch_size)\n",
    "    ACC_TRAIN.append(total_acc)\n",
    "    total_acc = 0\n",
    "    for n in range(0, (mnist.test.images[:1000,:].shape[0] // batch_size) * batch_size, batch_size):\n",
    "        batch_x = test_images[n: n + batch_size, :]\n",
    "        batch_y = np.zeros((batch_size, 10))\n",
    "        batch_y[np.arange(batch_size),mnist.test.labels[n:n+batch_size]] = 1.0\n",
    "        total_acc += sess.run(model.accuracy, \n",
    "                              feed_dict = {model.X : batch_x, \n",
    "                                           model.Y : batch_y})\n",
    "    total_acc /= (mnist.test.images[:1000,:].shape[0] // batch_size)\n",
    "    ACC_TEST.append(total_acc)\n",
    "    print('epoch: %d, accuracy train: %f, accuracy testing: %f'%(i+1, ACC_TRAIN[-1],ACC_TEST[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
