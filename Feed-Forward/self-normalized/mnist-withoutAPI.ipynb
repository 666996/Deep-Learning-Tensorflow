{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train-images-idx3-ubyte.gz\n",
      "Extracting train-labels-idx1-ubyte.gz\n",
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('', validation_size = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "        self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "        w1 = tf.Variable(tf.random_normal([784, 256], stddev=np.sqrt(1/784)))\n",
    "        b1 = tf.Variable(tf.random_normal([256],stddev=0))\n",
    "        w2 = tf.Variable(tf.random_normal([256, 100], stddev=np.sqrt(1/256)))\n",
    "        b2 = tf.Variable(tf.random_normal([100],stddev=0))\n",
    "        w3 = tf.Variable(tf.random_normal([100, 10], stddev=np.sqrt(1/100)))\n",
    "        b3 = tf.Variable(tf.random_normal([10],stddev=0))\n",
    "        feedforward = tf.nn.selu(tf.matmul(self.X, w1) + b1)\n",
    "        feeddropout = tf.contrib.nn.alpha_dropout(feedforward,0.5)\n",
    "        feedforward = tf.nn.selu(tf.matmul(feeddropout, w2) + b2)\n",
    "        feeddropout = tf.contrib.nn.alpha_dropout(feedforward,0.5)\n",
    "        self.logits = tf.matmul(feeddropout, w3) + b3\n",
    "        self.cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = self.Y, logits = self.logits))\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(self.cost)\n",
    "        correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epoch = 10\n",
    "\n",
    "train_images = (mnist.train.images - np.mean(mnist.train.images)) / np.std(mnist.train.images)\n",
    "test_images = (mnist.test.images - np.mean(mnist.test.images)) / np.std(mnist.test.images)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, accuracy train: 0.193693, accuracy testing: 0.294643\n",
      "epoch: 2, accuracy train: 0.392545, accuracy testing: 0.453125\n",
      "epoch: 3, accuracy train: 0.512153, accuracy testing: 0.552455\n",
      "epoch: 4, accuracy train: 0.584502, accuracy testing: 0.590402\n",
      "epoch: 5, accuracy train: 0.630425, accuracy testing: 0.629464\n",
      "epoch: 6, accuracy train: 0.663595, accuracy testing: 0.669643\n",
      "epoch: 7, accuracy train: 0.693059, accuracy testing: 0.704241\n",
      "epoch: 8, accuracy train: 0.712757, accuracy testing: 0.687500\n",
      "epoch: 9, accuracy train: 0.731070, accuracy testing: 0.716518\n",
      "epoch: 10, accuracy train: 0.745259, accuracy testing: 0.736607\n"
     ]
    }
   ],
   "source": [
    "LOSS, ACC_TRAIN, ACC_TEST = [], [], []\n",
    "for i in range(epoch):\n",
    "    total_loss, total_acc = 0, 0\n",
    "    for n in range(0, (mnist.train.images.shape[0] // batch_size) * batch_size, batch_size):\n",
    "        batch_x = train_images[n: n + batch_size, :]\n",
    "        batch_y = np.zeros((batch_size, 10))\n",
    "        batch_y[np.arange(batch_size),mnist.train.labels[n:n+batch_size]] = 1.0\n",
    "        cost, _ = sess.run([model.cost, model.optimizer], \n",
    "                           feed_dict = {model.X : batch_x, \n",
    "                                        model.Y : batch_y})\n",
    "        total_acc += sess.run(model.accuracy, \n",
    "                              feed_dict = {model.X : batch_x, \n",
    "                                           model.Y : batch_y})\n",
    "        total_loss += cost\n",
    "    total_loss /= (mnist.train.images.shape[0] // batch_size)\n",
    "    total_acc /= (mnist.train.images.shape[0] // batch_size)\n",
    "    ACC_TRAIN.append(total_acc)\n",
    "    total_acc = 0\n",
    "    for n in range(0, (mnist.test.images[:1000,:].shape[0] // batch_size) * batch_size, batch_size):\n",
    "        batch_x = test_images[n: n + batch_size, :]\n",
    "        batch_y = np.zeros((batch_size, 10))\n",
    "        batch_y[np.arange(batch_size),mnist.test.labels[n:n+batch_size]] = 1.0\n",
    "        total_acc += sess.run(model.accuracy, \n",
    "                              feed_dict = {model.X : batch_x, \n",
    "                                           model.Y : batch_y})\n",
    "    total_acc /= (mnist.test.images[:1000,:].shape[0] // batch_size)\n",
    "    ACC_TEST.append(total_acc)\n",
    "    print('epoch: %d, accuracy train: %f, accuracy testing: %f'%(i+1, ACC_TRAIN[-1],ACC_TEST[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
