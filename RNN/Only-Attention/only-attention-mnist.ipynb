{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train-images-idx3-ubyte.gz\n",
      "Extracting train-labels-idx1-ubyte.gz\n",
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_positional_encoding(inputs, num_units, zero_pad=False, scale=False):\n",
    "    T = inputs.get_shape().as_list()[1]\n",
    "    position_idx = tf.tile(tf.expand_dims(tf.range(T), 0), [tf.shape(inputs)[0], 1])\n",
    "    position_enc = np.array([[pos / np.power(10000, 2.*i/num_units) for i in range(num_units)] for pos in range(T)])\n",
    "    position_enc[:, 0::2] = np.sin(position_enc[:, 0::2])\n",
    "    position_enc[:, 1::2] = np.cos(position_enc[:, 1::2])\n",
    "    lookup_table = tf.convert_to_tensor(position_enc, tf.float32)\n",
    "    if zero_pad:\n",
    "        lookup_table = tf.concat([tf.zeros([1, num_units]), lookup_table[1:, :]], axis=0)\n",
    "    outputs = tf.nn.embedding_lookup(lookup_table, position_idx)\n",
    "    if scale:\n",
    "        outputs = outputs * num_units ** 0.5\n",
    "    return outputs\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        dimension_input = 28\n",
    "        dimension_output = 10\n",
    "        self.X = tf.placeholder(tf.float32, [None, dimension_input, dimension_input])\n",
    "        self.Y = tf.placeholder(tf.float32, [None, dimension_output])\n",
    "        x = self.X\n",
    "        x += sinusoidal_positional_encoding(x, dimension_input)\n",
    "        masks = tf.sign(self.X[:,:,0])\n",
    "        align = tf.squeeze(tf.layers.dense(x, 1, tf.tanh), -1)\n",
    "        paddings = tf.fill(tf.shape(align), float('-inf'))\n",
    "        align = tf.where(tf.equal(masks, 0), paddings, align)\n",
    "        align = tf.expand_dims(tf.nn.softmax(align), -1)\n",
    "        x = tf.squeeze(tf.matmul(tf.transpose(x, [0,2,1]), align), -1)\n",
    "        self.logits = tf.layers.dense(x, dimension_output)\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = self.logits, labels = self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = 1e-5).minimize(self.cost)\n",
    "        self.correct_pred = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "model = Model()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, avg loss nan, avg acc 0.098995, time taken 0.849506 secs\n",
      "epoch 2, avg loss nan, avg acc 0.098995, time taken 0.639864 secs\n",
      "epoch 3, avg loss nan, avg acc 0.098995, time taken 0.646694 secs\n",
      "epoch 4, avg loss nan, avg acc 0.098995, time taken 0.642822 secs\n",
      "epoch 5, avg loss nan, avg acc 0.098995, time taken 0.637193 secs\n",
      "epoch 6, avg loss nan, avg acc 0.098995, time taken 0.637640 secs\n",
      "epoch 7, avg loss nan, avg acc 0.098995, time taken 0.638074 secs\n",
      "epoch 8, avg loss nan, avg acc 0.098995, time taken 0.640802 secs\n",
      "epoch 9, avg loss nan, avg acc 0.098995, time taken 0.639443 secs\n",
      "epoch 10, avg loss nan, avg acc 0.098995, time taken 0.639225 secs\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCH):\n",
    "    last = time.time()\n",
    "    TOTAL_LOSS, ACCURACY = 0, 0\n",
    "    for n in range(0, (mnist.train.images.shape[0] // BATCH_SIZE) * BATCH_SIZE, BATCH_SIZE):\n",
    "        batch_x = mnist.train.images[n: n + BATCH_SIZE, :].reshape((-1, 28, 28))\n",
    "        acc, cost, _ = sess.run([model.accuracy, model.cost, model.optimizer], \n",
    "                           feed_dict = {model.X : batch_x, \n",
    "                                         model.Y : mnist.train.labels[n: n + BATCH_SIZE, :]})\n",
    "        ACCURACY += acc\n",
    "        TOTAL_LOSS += cost\n",
    "    TOTAL_LOSS /= (mnist.train.images.shape[0] // BATCH_SIZE)\n",
    "    ACCURACY /= (mnist.train.images.shape[0] // BATCH_SIZE)\n",
    "    print('epoch %d, avg loss %f, avg acc %f, time taken %f secs'%(i+1,TOTAL_LOSS,ACCURACY,time.time()-last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
