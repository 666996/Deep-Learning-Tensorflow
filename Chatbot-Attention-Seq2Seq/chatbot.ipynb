{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_dict(fromtext, totext):\n",
    "    \n",
    "    with open(fromtext, 'r') as fopen:\n",
    "        fromtext = fopen.read().split('\\n')\n",
    "    with open(totext, 'r') as fopen:\n",
    "        totext = fopen.read().split('\\n')\n",
    "        \n",
    "    if len(fromtext) != len(totext):\n",
    "        print 'from data-set must has equal length with to data-set, exiting..'\n",
    "        exit(0)\n",
    "\n",
    "    vocab_inputs = []; vocab_predict = []\n",
    "\n",
    "    # we tokenized each sentence in both dataset, turn into vocabulary.\n",
    "    for i in xrange(len(fromtext)):\n",
    "        vocab_inputs += fromtext[i].split(); vocab_predict += totext[i].split()\n",
    "\n",
    "    # Then we sorted our tokenized words from highest freq to lowest freq.\n",
    "    vocab_inputs = sorted(vocab_inputs, key = vocab_inputs.count,reverse = True)\n",
    "    vocab_predict = sorted(vocab_predict, key = vocab_predict.count,reverse = True)\n",
    "\n",
    "    d1 = dict((k,v) for v,k in enumerate(reversed(vocab_inputs)))\n",
    "    d2 = dict((k,v) for v,k in enumerate(reversed(vocab_predict)))\n",
    "\n",
    "    # Then we turned our sorted words into unique words, while maintaining the position of sorting.\n",
    "    vocab_inputs = ['PAD', 'EOS', 'UNK'] + sorted(d1, key = d1.get, reverse = True)\n",
    "    vocab_predict = ['PAD', 'EOS', 'UNK'] + sorted(d2, key = d2.get, reverse = True)\n",
    "\n",
    "    print 'vocab size for inputs: ' + str(len(vocab_inputs))\n",
    "    print 'vocab size for predict: ' + str(len(vocab_predict))\n",
    "\n",
    "    # Then turned into dictionary {'husein': 0, 'suka': 1.. n}\n",
    "    dict_inputs = dict(zip(vocab_inputs, [i for i in xrange(len(vocab_inputs))]))\n",
    "    dict_predict = dict(zip(vocab_predict, [i for i in xrange(len(vocab_predict))]))\n",
    "    \n",
    "    import pickle\n",
    "    with open('data/vocab_inputs.p', 'wb') as fopen:\n",
    "        pickle.dump(vocab_inputs, fopen)\n",
    "    with open('data/vocab_predict.p', 'wb') as fopen:\n",
    "        pickle.dump(vocab_predict, fopen)\n",
    "    with open('data/dict_inputs.p', 'wb') as fopen:\n",
    "        pickle.dump(dict_inputs, fopen)\n",
    "    with open('data/dict_predict.p', 'wb') as fopen:\n",
    "        pickle.dump(dict_predict, fopen)\n",
    "    with open('data/fromtext.p', 'wb') as fopen:\n",
    "        pickle.dump(fromtext, fopen)\n",
    "    with open('data/totext.p', 'wb') as fopen:\n",
    "        pickle.dump(totext, fopen)\n",
    "    \n",
    "    return vocab_inputs, vocab_predict, dict_inputs, dict_predict, fromtext, totext\n",
    "\n",
    "def feed(text, length, dictionary, From = True):\n",
    "    text_int = []\n",
    "    if From:\n",
    "        text_int_decode = [1]\n",
    "    strings = text.split()\n",
    "    for i in xrange(length):\n",
    "        try:\n",
    "            if From:\n",
    "                text_int.append(dictionary[strings[i]])\n",
    "                text_int_decode.append(dictionary[strings[i]])\n",
    "            else:\n",
    "                text_int.append(dictionary[strings[i]])\n",
    "        except KeyError:\n",
    "            text_int.append(2)\n",
    "            if From:\n",
    "                text_int_decode.append(2)\n",
    "        except IndexError:\n",
    "            text_int.append(0)\n",
    "            if From:\n",
    "                text_int_decode.append(0)\n",
    "                \n",
    "    text_int[length - 1] = 1\n",
    "    \n",
    "    if From:\n",
    "        del text_int_decode[len(text_int_decode) - 1]\n",
    "        return text_int, text_int_decode\n",
    "    else:\n",
    "        return text_int\n",
    "    \n",
    "def graph(LOSS):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set()\n",
    "\n",
    "    plt.plot([i for i in xrange(len(LOSS))], LOSS)\n",
    "    plt.title('loss vs epoch')\n",
    "    plt.show()\n",
    "    \n",
    "def label_to_text(label, vocab):\n",
    "    string = ''\n",
    "    for i in xrange(len(label)):\n",
    "        if label[i] == 0 or label[i] == 1:\n",
    "            continue\n",
    "        string += vocab[label[i]] + ' '\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fromtext_file = 'data/from'\n",
    "totext_file = 'data/to'\n",
    "\n",
    "length_sentence = 20\n",
    "size_layers = 1024\n",
    "num_layers = 1\n",
    "epoch = 30\n",
    "learning_rate = 0.0001\n",
    "\n",
    "Train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(self, num_layers, size_layers, length, learning_rate, vocab_size_input, vocab_size_output):\n",
    "        \n",
    "        self.encoder_inputs = tf.placeholder(shape = [length], dtype = tf.int32)\n",
    "        self.decoder_inputs = tf.placeholder(shape = [length], dtype = tf.int32)\n",
    "        self.decoder_targets = tf.placeholder(shape = [length], dtype = tf.int32)\n",
    "        \n",
    "        def lstm_cell():\n",
    "            return tf.nn.rnn_cell.LSTMCell(size_layers, activation = tf.nn.relu)\n",
    "\n",
    "        self.cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell() for _ in xrange(num_layers)])\n",
    "        \n",
    "        self.outputs, _ = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(encoder_inputs = [self.encoder_inputs], \n",
    "                                                                   decoder_inputs = [self.decoder_inputs], \n",
    "                                                                   cell = self.cell, \n",
    "                                                                   num_encoder_symbols = vocab_size_input, \n",
    "                                                                   num_decoder_symbols = vocab_size_input, \n",
    "                                                                   embedding_size = size_layers)\n",
    "        \n",
    "        self.decoder_logits = tf.contrib.layers.linear(self.outputs, len(vocab_predict))\n",
    "        self.decoder_prediction = tf.argmax(self.decoder_logits, 2)\n",
    "        self.cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels = tf.one_hot(self.decoder_targets, depth = vocab_size_output, dtype = tf.float32), \n",
    "                                                                logits = self.decoder_logits)\n",
    "        self.loss = tf.reduce_mean(self.cross_entropy)\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load embedded files..\n",
      "done load embedded files\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "try:\n",
    "    print \"load embedded files..\"\n",
    "    with open('data/vocab_inputs.p', 'rb') as fopen:\n",
    "        vocab_inputs = pickle.load(fopen)\n",
    "    with open('data/vocab_predict.p', 'rb') as fopen:\n",
    "        vocab_predict = pickle.load(fopen)\n",
    "    with open('data/dict_inputs.p', 'rb') as fopen:\n",
    "        dict_inputs = pickle.load(fopen)\n",
    "    with open('data/dict_predict.p', 'rb') as fopen:\n",
    "        dict_predict = pickle.load(fopen)\n",
    "    with open('data/fromtext.p', 'rb') as fopen:\n",
    "        fromtext = pickle.load(fopen)\n",
    "    with open('data/totext.p', 'rb') as fopen:\n",
    "        totext = pickle.load(fopen)\n",
    "    print 'done load embedded files'\n",
    "except Exception as e:\n",
    "    print str(e) + ', processing embedded files, this might takes several minutes'\n",
    "    vocab_inputs, vocab_predict, dict_inputs, dict_predict, fromtext, totext = return_dict(fromtext_file, totext_file)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model(num_layers, size_layers, length_sentence, learning_rate, len(vocab_inputs), len(vocab_predict))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "location = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomtest():\n",
    "    import random\n",
    "    randomselect = random.randint(30, 100)\n",
    "    for i in xrange(randomselect):\n",
    "        num = random.randint(0, len(fromtext) - 1)\n",
    "        input_seq_encode, input_seq_decode = feed(fromtext[num], length_sentence, dict_inputs, True)\n",
    "        predict = sess.run(model.decoder_prediction, feed_dict = {model.encoder_inputs : input_seq_encode, model.decoder_inputs : input_seq_decode})\n",
    "        print 'sentence: ' + str(i + 1)\n",
    "        print 'input: ' + fromtext[num]\n",
    "        print 'predict respond: ' + str(label_to_text(predict[0, :], vocab_predict))\n",
    "        print 'actual respond: ' + totext[num] + '\\n'\n",
    "\n",
    "def test():\n",
    "    sentence = raw_input('> ')\n",
    "    while sentence:\n",
    "        input_seq_encode, input_seq_decode = feed(sentence, length_sentence, dict_inputs, True)\n",
    "        predict = sess.run(model.decoder_prediction, feed_dict = {model.encoder_inputs : input_seq_encode, model.decoder_inputs : input_seq_decode})\n",
    "        print label_to_text(predict[0, :], vocab_predict)\n",
    "        sentence = raw_input('> ')\n",
    "        \n",
    "def train():\n",
    "    LOSS = []\n",
    "    for i in xrange(epoch):\n",
    "        total_loss = 0\n",
    "        lasttime = time.time()\n",
    "        for w in xrange(len(fromtext)):\n",
    "            input_seq_encode, input_seq_decode = feed(fromtext[w], length_sentence, dict_inputs, True)\n",
    "            output_seq = feed(totext[w], length_sentence, dict_predict, False)\n",
    "            _, losses = sess.run([model.optimizer, model.loss], feed_dict = {model.encoder_inputs : input_seq_encode, model.decoder_inputs : input_seq_decode, \n",
    "                                                                 model.decoder_targets : output_seq })\n",
    "            total_loss += losses\n",
    "            \n",
    "            if (w + 1) % 200 == 0:\n",
    "                print 'done process: ' + str(w + 1)\n",
    "                \n",
    "        total_loss = total_loss / (len(fromtext) * 1.0)\n",
    "        LOSS.append(total_loss)\n",
    "        print 'epoch: ' + str(i + 1) + ', total loss: ' + str(total_loss) + ', s/epoch: ' + str(time.time() - lasttime)\n",
    "        saver.save(sess, location + \"/model.ckpt\")\n",
    "    graph(LOSS)\n",
    "    randomtest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 1, total loss: 1.39197879303, s/epoch: 39.6266481876\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 2, total loss: 1.12367172805, s/epoch: 39.450838089\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 3, total loss: 0.942006279869, s/epoch: 39.4433028698\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 4, total loss: 0.771754278118, s/epoch: 39.4305529594\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 5, total loss: 0.662924866127, s/epoch: 39.3509840965\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 6, total loss: 0.609594779034, s/epoch: 39.3231899738\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 7, total loss: 0.573206361217, s/epoch: 39.3578619957\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 8, total loss: 0.539124352264, s/epoch: 39.3337221146\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 9, total loss: 0.507157790924, s/epoch: 39.2932999134\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 10, total loss: 0.480844903617, s/epoch: 39.3834221363\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 11, total loss: 0.458132122718, s/epoch: 39.3205349445\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 12, total loss: 0.430211526056, s/epoch: 39.3610038757\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 13, total loss: 0.411208853364, s/epoch: 39.3242521286\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 14, total loss: 0.396315333824, s/epoch: 39.3262479305\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 15, total loss: 0.38128133052, s/epoch: 39.3792409897\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 16, total loss: 0.368658284875, s/epoch: 39.3573410511\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 17, total loss: 0.360609663699, s/epoch: 39.3631541729\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 18, total loss: 0.35237990214, s/epoch: 39.3535609245\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 19, total loss: 0.351172921684, s/epoch: 39.3877420425\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 20, total loss: 0.351473943585, s/epoch: 39.3314261436\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 21, total loss: 0.348519326796, s/epoch: 39.3324890137\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 22, total loss: 0.346171664947, s/epoch: 39.3208851814\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 23, total loss: 0.336946827884, s/epoch: 39.2423970699\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 24, total loss: 0.332499537139, s/epoch: 39.2208919525\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 25, total loss: 0.337134929866, s/epoch: 39.2571239471\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 26, total loss: 0.333970946876, s/epoch: 39.2406790257\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 27, total loss: 0.333845229637, s/epoch: 39.2454900742\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 28, total loss: 0.330916870242, s/epoch: 39.2576639652\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 29, total loss: 0.330183352165, s/epoch: 39.2550671101\n",
      "done process: 200\n",
      "done process: 400\n",
      "done process: 600\n",
      "epoch: 30, total loss: 0.331749237082, s/epoch: 39.2322559357\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8458f41210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 1\n",
      "input: bernama The Company\n",
      "predict respond: Keadaan tidak \n",
      "actual respond: Keadaan tidak baik Awak?\n",
      "\n",
      "sentence: 2\n",
      "input: Ruparupanya awak boleh\n",
      "predict respond: Dia pulihkan akan \n",
      "actual respond: Dia cakap dia dapat lihat\n",
      "\n",
      "sentence: 3\n",
      "input: Tuang ke dalam tandas\n",
      "predict respond: Apabila kita melihat keunikan kita \n",
      "actual respond: Apabila kita melihat keunikan kita\n",
      "\n",
      "sentence: 4\n",
      "input: Saya boleh lakukan ini!\n",
      "predict respond: kesunyian maksud kau \n",
      "actual respond: Itulah maksud aku\n",
      "\n",
      "sentence: 5\n",
      "input: Negara tunggu awak\n",
      "predict respond: Jadi, bagaimana sekarang? \n",
      "actual respond: Jadi, bagaimana sekarang?\n",
      "\n",
      "sentence: 6\n",
      "input: bukan kerana kita sependapat\n",
      "predict respond: Di dalam itu \n",
      "actual respond: Di dalam itu\n",
      "\n",
      "sentence: 7\n",
      "input: Jawab saya\n",
      "predict respond: Saya tahu \n",
      "actual respond: Saya tahu\n",
      "\n",
      "sentence: 8\n",
      "input: bunuh orang yang membelot\n",
      "predict respond: Biar saya fahamkan \n",
      "actual respond: Biar saya cuba fahamkan\n",
      "\n",
      "sentence: 9\n",
      "input: Ya, dia juga pernah kata,\n",
      "predict respond: Awak perlu jalankan beratusratus \n",
      "actual respond: Saya perlu jalankan beratusratus\n",
      "\n",
      "sentence: 10\n",
      "input: besar macam itu, betul?\n",
      "predict respond: Tidak Awak menyembunyikan kerana \n",
      "actual respond: Tidak Awak datang kerana awak\n",
      "\n",
      "sentence: 11\n",
      "input: budak Tweener itu?\n",
      "predict respond: Kenapa aku tak \n",
      "actual respond: Kenapa aku tak berasa terkejut?\n",
      "\n",
      "sentence: 12\n",
      "input: Paling kurang awak boleh\n",
      "predict respond: perbualanperbualan kita kau? akan \n",
      "actual respond: perbualanperbualan kita\n",
      "\n",
      "sentence: 13\n",
      "input: Awak patut dengar apa\n",
      "predict respond: Lebih dengan Sara baikbaik \n",
      "actual respond: bercakap dengan Sara\n",
      "\n",
      "sentence: 14\n",
      "input: dan awak juga akan selamat\n",
      "predict respond: kepentingan setuju pun \n",
      "actual respond: belum setuju pun\n",
      "\n",
      "sentence: 15\n",
      "input: Apa?\n",
      "predict respond: apaapa \n",
      "actual respond: Awak simpanlah itu\n",
      "\n",
      "sentence: 16\n",
      "input: Banyak kali saya ditangkap\n",
      "predict respond: Linc, Kalau tak pernah \n",
      "actual respond: Linc, mereka tidak pernah\n",
      "\n",
      "sentence: 17\n",
      "input: Van tiba dalam masa setengah jam\n",
      "predict respond: ubat yang mereka \n",
      "actual respond: ubat yang mereka\n",
      "\n",
      "sentence: 18\n",
      "input: Jawab saya\n",
      "predict respond: Saya tahu \n",
      "actual respond: Saya tahu\n",
      "\n",
      "sentence: 19\n",
      "input: mempersoalkan keinginanNya\n",
      "predict respond: di Hanka \n",
      "actual respond: di Hanka\n",
      "\n",
      "sentence: 20\n",
      "input: Kalau awak ada masalah dengan\n",
      "predict respond: Dan tidak terkawal \n",
      "actual respond: Dan tidak terkawal\n",
      "\n",
      "sentence: 21\n",
      "input: Dan ini\n",
      "predict respond: kerana tunai \n",
      "actual respond: wang tunai di dalamnya\n",
      "\n",
      "sentence: 22\n",
      "input: membunuh Abruzzi\n",
      "predict respond: apa yang awak \n",
      "actual respond: apa yang awak ada\n",
      "\n",
      "sentence: 23\n",
      "input: Michael, awak bunuh saya,\n",
      "predict respond: Awak semula buat \n",
      "actual respond: Awak mahu dia buat sesuatu,\n",
      "\n",
      "sentence: 24\n",
      "input: Sara\n",
      "predict respond: saya \n",
      "actual respond: saya ada bawa seseorang\n",
      "\n",
      "sentence: 25\n",
      "input: Saya akan keluarkan\n",
      "predict respond: kesunyian saraf orangorang \n",
      "actual respond: di mana orangorang\n",
      "\n",
      "sentence: 26\n",
      "input: dapatkan baju yang perlu\n",
      "predict respond: Aku terasa \n",
      "actual respond: Aku terasa lemas\n",
      "\n",
      "sentence: 27\n",
      "input: Apa yang awak cakap?\n",
      "predict respond: kawan saya bekerja di \n",
      "actual respond: kawan saya pernah bekerja di sini\n",
      "\n",
      "sentence: 28\n",
      "input: baik kerana jumpa awak\n",
      "predict respond: isyarat data \n",
      "actual respond: isyarat data\n",
      "\n",
      "sentence: 29\n",
      "input: Baik\n",
      "predict respond: kerja jentera \n",
      "actual respond: Kami berjaya dapatkan\n",
      "\n",
      "sentence: 30\n",
      "input: Kita akan pergi lepas makan malam,\n",
      "predict respond: Orang kawan dari tempat \n",
      "actual respond: tiket keluar dari tempat ini\n",
      "\n",
      "sentence: 31\n",
      "input: Tak mengapa Saya ejen persekutuan\n",
      "predict respond: masih Tetapi, dia \n",
      "actual respond: Tidak Tetapi, dia\n",
      "\n",
      "sentence: 32\n",
      "input: Saya akan lahirkan anak awak\n",
      "predict respond: kesunyian saraf awak \n",
      "actual respond: sistem saraf awak\n",
      "\n",
      "sentence: 33\n",
      "input: Agak bagus\n",
      "predict respond: Tetapi masalah ini \n",
      "actual respond: Tetapi masalah ini nampaknya\n",
      "\n",
      "sentence: 34\n",
      "input: Sara\n",
      "predict respond: saya \n",
      "actual respond: Apa awak mahu?\n",
      "\n",
      "sentence: 35\n",
      "input: sehingga dia bangun\n",
      "predict respond: Awak dialah \n",
      "actual respond: Awak cakap dialah sebab\n",
      "\n",
      "sentence: 36\n",
      "input: Masa itu ialah sekarang\n",
      "predict respond: Ia boleh membawa kesan \n",
      "actual respond: Ia boleh membawa kesan\n",
      "\n",
      "sentence: 37\n",
      "input: Baik, panggil Scofield\n",
      "predict respond: Kerosakan itu \n",
      "actual respond: Kerosakan itu\n",
      "\n",
      "sentence: 38\n",
      "input: melainkan awak boleh\n",
      "predict respond: Dia opera akan \n",
      "actual respond: Dia beritahu apa mereka boleh\n",
      "\n",
      "sentence: 39\n",
      "input: Mereka itu ialah awak\n",
      "predict respond: Cakap saya membawa \n",
      "actual respond: yang saya percayakan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if Train:\n",
    "        train()\n",
    "    else:\n",
    "        randomtest()\n",
    "        \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
