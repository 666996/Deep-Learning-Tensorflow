{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import multiprocessing\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train-images-idx3-ubyte.gz\n",
      "Extracting train-labels-idx1-ubyte.gz\n",
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = mnist.train._images.reshape((-1,28,28,1))\n",
    "train_Y =mnist.train._labels\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = mnist.test._images.reshape((-1,28,28,1))\n",
    "test_Y =mnist.test._labels\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def convert_to(dataset, labels, name, i):\n",
    "    if not os.path.exists(name):\n",
    "        os.mkdir(name)\n",
    "    filename = os.path.join(name,'file-%d.tfrecords'%(i))\n",
    "    print('writing %s, cpu %d'%(filename,i))\n",
    "    with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "        for index in range(dataset.shape[0]):\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'label': _int64_feature(int(labels[index])),\n",
    "                'image':_bytes_feature(dataset[index].tostring())}))\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing train/file-0.tfrecords, cpu 0\n",
      "writing train/file-1.tfrecords, cpu 1\n",
      "writing test/file-0.tfrecords, cpu 0\n",
      "writing test/file-1.tfrecords, cpu 1\n"
     ]
    }
   ],
   "source": [
    "cpu_cores = 2\n",
    "train_idx = np.linspace(0, train_X.shape[0], cpu_cores + 1, dtype=np.int)\n",
    "test_idx = np.linspace(0, test_X.shape[0], cpu_cores + 1, dtype=np.int)\n",
    "pool = multiprocessing.Pool(processes=cpu_cores)\n",
    "\n",
    "for p in range(cpu_cores):\n",
    "    pool.apply_async(convert_to,\n",
    "                (train_X[train_idx[p]:train_idx[p + 1] - 1], \n",
    "                 train_Y[train_idx[p]:train_idx[p + 1] - 1],'train', p,))\n",
    "    \n",
    "for p in range(cpu_cores):\n",
    "    pool.apply_async(convert_to,\n",
    "                (test_X[train_idx[p]:test_idx[p + 1] - 1], \n",
    "                 test_Y[train_idx[p]:test_idx[p + 1] - 1],'test', p,))\n",
    "    \n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={'image': tf.FixedLenFeature([], tf.string),\n",
    "                  'label': tf.FixedLenFeature([], tf.int64)})\n",
    "    image = tf.decode_raw(features['image'], tf.float32)\n",
    "    image = tf.reshape(image, [28,28,1])\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "batch_size = 128\n",
    "epoch = 5\n",
    "filename_queue = tf.train.string_input_producer(['train/'+i for i in os.listdir('train')], num_epochs=epoch)\n",
    "image, label = read_and_decode(filename_queue)\n",
    "images, labels = tf.train.shuffle_batch([image, label], batch_size=batch_size, num_threads=12,\n",
    "                                        capacity=train_X.shape[0],\n",
    "                                        min_after_dequeue=1000, allow_smaller_final_batch=False)\n",
    "    \n",
    "def convolutionize(x, conv_w, h = 1):\n",
    "    return tf.nn.conv2d(input = x, filter = conv_w, strides = [1, h, h, 1], padding = 'SAME')\n",
    "\n",
    "def pooling(wx):\n",
    "    return tf.nn.max_pool(wx, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "\n",
    "def create_network(X, scope='conv',reuse=False):\n",
    "    with tf.variable_scope(scope,reuse=reuse):\n",
    "        w1 = tf.Variable(tf.random_normal([3, 3, 1, 2], stddev = 0.5))\n",
    "        b1 = tf.Variable(tf.zeros(shape = [2]))\n",
    "        w2 = tf.Variable(tf.random_normal([3, 3, 2, 4], stddev = 0.5))\n",
    "        b2 = tf.Variable(tf.zeros(shape = [4]))\n",
    "        w3 = tf.Variable(tf.random_normal([3, 3, 4, 8], stddev = 0.5))\n",
    "        b3 = tf.Variable(tf.zeros(shape = [8]))\n",
    "        w4 = tf.Variable(tf.random_normal([128, 10], stddev = 0.5))\n",
    "        b4 = tf.Variable(tf.zeros(shape = [10]))\n",
    "\n",
    "        conv1 = pooling(tf.nn.relu(convolutionize(X, w1) + b1))\n",
    "        conv2 = pooling(tf.nn.relu(convolutionize(conv1, w2) + b2))\n",
    "        conv3 = pooling(tf.nn.relu(convolutionize(conv2, w3) + b3))\n",
    "        conv3 = tf.reshape(conv3, [-1, 128])\n",
    "        return tf.matmul(conv3, w4) + b4\n",
    "\n",
    "logits = create_network(images)\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,logits=logits)\n",
    "global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(1e-3).minimize(cost,global_step=global_step)\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1,output_type=tf.int32), labels)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init_op = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss 50.056328, accuracy 0.078125\n",
      "step 200, loss 3.715207, accuracy 0.187500\n",
      "step 400, loss 2.060507, accuracy 0.250000\n",
      "step 600, loss 1.960434, accuracy 0.250000\n",
      "step 800, loss 1.778734, accuracy 0.406250\n",
      "step 1000, loss 1.670723, accuracy 0.406250\n",
      "step 1200, loss 1.288428, accuracy 0.515625\n",
      "step 1400, loss 1.047216, accuracy 0.648438\n",
      "step 1600, loss 0.933371, accuracy 0.656250\n",
      "step 1800, loss 0.846617, accuracy 0.765625\n",
      "step 2000, loss 0.932054, accuracy 0.703125\n",
      "Done training for 5 epochs, 2148 steps.\n"
     ]
    }
   ],
   "source": [
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "try:\n",
    "    step = sess.run(global_step)\n",
    "    while not coord.should_stop():\n",
    "        acc,loss,_,_,_ = sess.run([accuracy, cost, optimizer,images, labels])\n",
    "        if step % 200 == 0:\n",
    "            print('step %d, loss %f, accuracy %f'%(step,loss,acc))\n",
    "        step = sess.run(global_step)\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print('Done training for %d epochs, %d steps.' % (epoch, step))\n",
    "finally:\n",
    "    coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
