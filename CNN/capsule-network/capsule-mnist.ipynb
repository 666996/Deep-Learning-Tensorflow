{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train-images-idx3-ubyte.gz\n",
      "Extracting train-labels-idx1-ubyte.gz\n",
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('', validation_size = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(X, epsilon = 1e-9):\n",
    "    vec_squared_norm = tf.reduce_sum(tf.square(X), -2, keep_dims=True)\n",
    "    scalar_factor = vec_squared_norm / (1 + vec_squared_norm) / tf.sqrt(vec_squared_norm + epsilon)\n",
    "    return scalar_factor * X\n",
    "\n",
    "def conv_layer(X, num_output, num_vector, kernel=None, stride=None):\n",
    "    global batch_size\n",
    "    capsules = tf.contrib.layers.conv2d(X, num_output * num_vector,\n",
    "                                        kernel, stride, padding=\"VALID\", activation_fn=tf.nn.relu)\n",
    "    capsules = tf.reshape(capsules, (batch_size, -1, num_vector, 1))\n",
    "    return squash(capsules)\n",
    "\n",
    "def routing(X, b_IJ, routing_times = 2):\n",
    "    global batch_size\n",
    "    w = tf.Variable(tf.truncated_normal([1, 1152, 10, 8, 16], stddev=1e-1))\n",
    "    X = tf.tile(X, [1, 1, 10, 1, 1])\n",
    "    w = tf.tile(w, [batch_size, 1, 1, 1, 1])\n",
    "    u_hat = tf.matmul(w, X, transpose_a=True)\n",
    "    u_hat_stopped = tf.stop_gradient(u_hat)\n",
    "    for i in range(routing_times):\n",
    "        c_IJ = tf.nn.softmax(b_IJ, dim=2)\n",
    "        if i == routing_times - 1:\n",
    "            s_J = tf.multiply(c_IJ, u_hat)\n",
    "            s_J = tf.reduce_sum(s_J, axis=1, keep_dims=True)\n",
    "            v_J = squash(s_J)\n",
    "        else:\n",
    "            s_J = tf.multiply(c_IJ, u_hat_stopped)\n",
    "            s_J = tf.reduce_sum(s_J, axis=1, keep_dims=True)\n",
    "            v_J = squash(s_J)\n",
    "            v_J_tiled = tf.tile(v_J, [1, 1152, 1, 1, 1])\n",
    "            u_produce_v = tf.matmul(u_hat_stopped, v_J_tiled, transpose_a=True)\n",
    "            b_IJ += u_produce_v\n",
    "    return v_J\n",
    "\n",
    "def fully_conn_layer(X, num_output):\n",
    "    global batch_size\n",
    "    X_ = tf.reshape(X, shape=(batch_size, -1, 1, X.shape[-2].value, 1))\n",
    "    b_IJ = tf.constant(np.zeros([batch_size, 1152, num_output, 1, 1], dtype=np.float32))\n",
    "    capsules = routing(X_, b_IJ, routing_times = 2)\n",
    "    capsules = tf.squeeze(capsules, axis=1)\n",
    "    return capsules\n",
    "\n",
    "class CapsuleNetwork:\n",
    "    def __init__(self, batch_size, learning_rate, regularization_scale=0.392,\n",
    "                 epsilon=1e-8, m_plus=0.9, m_minus=0.1, lambda_val=0.5):\n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "        self.Y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "        conv1 = tf.contrib.layers.conv2d(self.X, num_outputs=256,\n",
    "                                             kernel_size=9, stride=1,\n",
    "                                             padding='VALID')\n",
    "        caps1 = conv_layer(conv1, 32, 8, 9, 2)\n",
    "        caps2 = fully_conn_layer(caps1, 10)\n",
    "        v_length = tf.sqrt(tf.reduce_sum(tf.square(caps2),axis=2, keep_dims=True) + epsilon)\n",
    "        self.logits = tf.nn.softmax(v_length, dim=1)[:,:,0,0]\n",
    "        masked_v = tf.multiply(tf.squeeze(caps2), tf.reshape(self.Y, (-1, 10, 1)))\n",
    "        v_length = tf.sqrt(tf.reduce_sum(tf.square(caps2), axis=2, keep_dims=True) + epsilon)\n",
    "        vector_j = tf.reshape(masked_v, shape=(batch_size, -1))\n",
    "        fc1 = tf.contrib.layers.fully_connected(vector_j, num_outputs=512)\n",
    "        fc2 = tf.contrib.layers.fully_connected(fc1, num_outputs=1024)\n",
    "        decoded = tf.contrib.layers.fully_connected(fc2, num_outputs=784, activation_fn=tf.sigmoid)\n",
    "        max_l = tf.square(tf.maximum(0., m_plus - v_length))\n",
    "        max_r = tf.square(tf.maximum(0., v_length - m_minus))\n",
    "        max_l = tf.reshape(max_l, shape=(batch_size, -1))\n",
    "        max_r = tf.reshape(max_r, shape=(batch_size, -1))\n",
    "        L_c = self.Y * max_l + lambda_val * (1 - self.Y) * max_r\n",
    "        margin_loss = tf.reduce_mean(tf.reduce_sum(L_c, axis=1))\n",
    "        origin = tf.reshape(self.X, shape=(batch_size, -1))\n",
    "        squared = tf.reduce_mean(tf.square(decoded - origin))\n",
    "        self.cost = margin_loss + regularization_scale * squared\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.cost)\n",
    "        correct_prediction = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "epoch = 5\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = CapsuleNetwork(batch_size, learning_rate)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, accuracy train: 0.949820, accuracy testing: 0.989955\n",
      "epoch: 2, accuracy train: 0.991186, accuracy testing: 0.989955\n",
      "epoch: 3, accuracy train: 0.994474, accuracy testing: 0.989955\n",
      "epoch: 4, accuracy train: 0.996444, accuracy testing: 0.989955\n"
     ]
    }
   ],
   "source": [
    "LOSS, ACC_TRAIN, ACC_TEST = [], [], []\n",
    "for i in range(epoch):\n",
    "    total_loss, total_acc = 0, 0\n",
    "    for n in range(0, (mnist.train.images.shape[0] // batch_size) * batch_size, batch_size):\n",
    "        batch_x = mnist.train.images[n: n + batch_size, :].reshape((-1, 28, 28, 1))\n",
    "        batch_y = np.zeros((batch_size, 10))\n",
    "        for k in range(batch_size):\n",
    "            batch_y[k, mnist.train.labels[n + k]] = 1.0\n",
    "        cost, _ = sess.run([model.cost, model.optimizer], \n",
    "                           feed_dict = {model.X : batch_x, \n",
    "                                        model.Y : batch_y})\n",
    "        total_acc += sess.run(model.accuracy, \n",
    "                              feed_dict = {model.X : batch_x, \n",
    "                                           model.Y : batch_y})\n",
    "        total_loss += cost\n",
    "    total_loss /= (mnist.train.images.shape[0] // batch_size)\n",
    "    total_acc /= (mnist.train.images.shape[0] // batch_size)\n",
    "    ACC_TRAIN.append(total_acc)\n",
    "    total_acc = 0\n",
    "    for n in range(0, (mnist.test.images[:1000,:].shape[0] // batch_size) * batch_size, batch_size):\n",
    "        batch_x = mnist.test.images[n: n + batch_size, :].reshape((-1, 28, 28, 1))\n",
    "        batch_y = np.zeros((batch_size, 10))\n",
    "        for k in range(batch_size):\n",
    "            batch_y[k, mnist.test.labels[n + k]] = 1.0\n",
    "        total_acc += sess.run(model.accuracy, \n",
    "                              feed_dict = {model.X : batch_x, \n",
    "                                           model.Y : batch_y})\n",
    "    total_acc /= (mnist.test.images[:1000,:].shape[0] // batch_size)\n",
    "    ACC_TEST.append(total_acc)\n",
    "    print('epoch: %d, accuracy train: %f, accuracy testing: %f'%(i+1, ACC_TRAIN[-1],ACC_TEST[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
