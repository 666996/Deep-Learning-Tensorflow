{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train-images-idx3-ubyte.gz\n",
      "Extracting train-labels-idx1-ubyte.gz\n",
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    x = tf.clip_by_value(x, -1.0, 1.0)\n",
    "    return x + tf.stop_gradient(tf.sign(x) - x)\n",
    "\n",
    "def weight_bias(shape):\n",
    "    init = tf.random_uniform(shape, -1.0, 1.0)\n",
    "    x, y = tf.Variable(init), tf.Variable(init)\n",
    "    coeff = np.float32(1./np.sqrt(1.5/ (np.prod(shape[:-2]) * (shape[-2] + shape[-1]))))\n",
    "    tmp = y + coeff * (x - y)\n",
    "    tmp = tf.clip_by_value(tmp, -1.0, 1.0)\n",
    "    tmp = tf.group(x.assign(tmp), y.assign(tmp))\n",
    "    tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, tmp)\n",
    "    x = tf.clip_by_value(x, -1.0, 1.0)\n",
    "    xbin = tf.sign(x) * tf.reduce_mean(tf.abs(x), axis=[0, 1, 2])\n",
    "    x = x + tf.stop_gradient(xbin - x)\n",
    "    return x, tf.Variable(tf.constant(0.1, shape=[shape[-1]]))\n",
    "\n",
    "def batch_norm(x, epsilon, decay=0.9,is_training=True):\n",
    "    return tf.contrib.layers.batch_norm(x, decay=decay, center=True, scale=True,\n",
    "                                        epsilon=epsilon, updates_collections=None, \n",
    "                                        is_training=is_training, trainable=True, fused=True)\n",
    "\n",
    "def layer(x,filter_output,filter_size=[1, 1], stride=[1, 1],pool=None,\n",
    "         activate='bin',norm=True, epsilon=0.0001, padding='SAME'):\n",
    "    shape = filter_size + [x.shape[-1].value, filter_output]\n",
    "    W, b = weight_bias(shape)\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, *stride, 1], padding=padding) + b\n",
    "    if activate == 'bin':\n",
    "        if pool is not None:\n",
    "            x = tf.nn.max_pool(x, ksize=[1, *pool[0], 1], strides=[1, *pool[-1], 1], padding='VALID')\n",
    "        if norm:\n",
    "            x = batch_norm(x, epsilon)\n",
    "    else:\n",
    "        if norm:\n",
    "            x = batch_norm(x, epsilon)\n",
    "        if pool is not None:\n",
    "            x = tf.nn.max_pool(x, ksize=[1, *pool[0], 1], strides=[1, *pool[-1], 1], padding='VALID')\n",
    "    if activate == 'bin':\n",
    "        return activation(x)\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.LEARNING_RATE = tf.placeholder(tf.float32)\n",
    "        self.X = tf.placeholder(tf.float32, [None, 28,28,1])\n",
    "        self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "        feed = layer(self.X, 32, filter_size=[3, 3])\n",
    "        feed = layer(feed, 32, filter_size=[3, 3], pool=([2, 2], [2, 2]))\n",
    "        feed = layer(feed, 64, filter_size=[3, 3])\n",
    "        feed = layer(feed, 64, filter_size=[3, 3], pool=([2, 2], [2, 2]))\n",
    "        feed = layer(feed, 128, filter_size=[3, 3])\n",
    "        feed = layer(feed, 128, filter_size=[3, 3], pool=([2, 2], [2, 2]))\n",
    "        feed = layer(feed, 512, filter_size=[3, 3], padding='VALID')\n",
    "        feed = layer(feed, 512)\n",
    "        self.logits = tf.reshape(layer(feed, 10, activate='none'),(-1,10))\n",
    "        self.cost = tf.reduce_mean(tf.square(tf.losses.hinge_loss(self.logits, self.Y)))\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.LEARNING_RATE).minimize(self.cost)\n",
    "        correct_prediction = tf.equal(tf.argmax(self.Y,1), tf.argmax(self.logits,1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "model = Model()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "LR_DECAY = (0.0000003/LEARNING_RATE)**(1.0/EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, avg loss 0.895331, avg acc 0.505263, time taken 19.651270 secs\n",
      "epoch 2, avg loss 0.827856, avg acc 0.663553, time taken 19.037146 secs\n",
      "epoch 3, avg loss 0.822051, avg acc 0.693364, time taken 19.041926 secs\n",
      "epoch 4, avg loss 0.820354, avg acc 0.706021, time taken 19.041143 secs\n",
      "epoch 5, avg loss 0.819569, avg acc 0.712777, time taken 19.042750 secs\n",
      "epoch 6, avg loss 0.819425, avg acc 0.712504, time taken 19.045459 secs\n",
      "epoch 7, avg loss 0.819440, avg acc 0.712704, time taken 19.046358 secs\n",
      "epoch 8, avg loss 0.819004, avg acc 0.715454, time taken 19.052731 secs\n",
      "epoch 9, avg loss 0.819031, avg acc 0.717967, time taken 19.050926 secs\n",
      "epoch 10, avg loss 0.819136, avg acc 0.716255, time taken 19.048928 secs\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCH):\n",
    "    last = time.time()\n",
    "    TOTAL_LOSS, ACCURACY = 0, 0\n",
    "    for n in range(0, (mnist.train.images.shape[0] // BATCH_SIZE) * BATCH_SIZE, BATCH_SIZE):\n",
    "        batch_x = mnist.train.images[n: n + BATCH_SIZE, :].reshape((-1, 28, 28, 1))\n",
    "        acc, cost, _ = sess.run([model.accuracy, model.cost, model.optimizer], \n",
    "                           feed_dict = {model.X : batch_x, \n",
    "                                         model.Y : mnist.train.labels[n: n + BATCH_SIZE, :],\n",
    "                                        model.LEARNING_RATE:LEARNING_RATE})\n",
    "        ACCURACY += acc\n",
    "        TOTAL_LOSS += cost\n",
    "    LEARNING_RATE *= LR_DECAY\n",
    "    TOTAL_LOSS /= (mnist.train.images.shape[0] // BATCH_SIZE)\n",
    "    ACCURACY /= (mnist.train.images.shape[0] // BATCH_SIZE)\n",
    "    print('epoch %d, avg loss %f, avg acc %f, time taken %f secs'%(i+1,TOTAL_LOSS,ACCURACY,time.time()-last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
