{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import functools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train-images-idx3-ubyte.gz\n",
      "Extracting train-labels-idx1-ubyte.gz\n",
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, i, filters, kernel_size):\n",
    "    x_copy = x\n",
    "    pad_len = (kernel_size - 1) * i\n",
    "    x = tf.pad(x, [[0, 0], [pad_len, 0], [0, 0]])\n",
    "    x = tf.layers.conv1d(x, filters, kernel_size, dilation_rate=i,padding='valid')\n",
    "    tanh = tf.nn.tanh(x)\n",
    "    sigmoid = tf.nn.sigmoid(x)\n",
    "    x = tanh * sigmoid\n",
    "    x = tf.layers.dropout(x, 0.05, noise_shape=[x.shape[0], x.shape[1], tf.constant(1)])\n",
    "    x = tf.layers.conv1d(x,filters,1,padding='same')\n",
    "    return x_copy + x, x\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, filters=32,kernel_size=4,dilations=[1,2,4,8],\n",
    "                stacks=8):\n",
    "        self.X = tf.placeholder(tf.float32, [None, 28, 28])\n",
    "        self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "        padded_x = tf.pad(self.X, [[0, 0], [(filters - 1), 0], [0, 0]])\n",
    "        padded_x = tf.layers.conv1d(padded_x, filters, kernel_size, dilation_rate=1)\n",
    "        for s in range(stacks):\n",
    "            for i in dilations:\n",
    "                padded_x, skip_out = residual_block(padded_x, i, filters, kernel_size)\n",
    "        self.logits = tf.layers.dense(padded_x[:,-1], 10)\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = self.logits, labels = self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = 0.002).minimize(self.cost)\n",
    "        self.correct_pred = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "model = Model()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, avg loss 0.276650, avg acc 0.918925, time taken 32.548837 secs\n",
      "epoch 2, avg loss 0.106526, avg acc 0.966892, time taken 30.491681 secs\n",
      "epoch 3, avg loss 0.068610, avg acc 0.977892, time taken 30.623620 secs\n",
      "epoch 4, avg loss 0.056535, avg acc 0.981807, time taken 30.625988 secs\n",
      "epoch 5, avg loss 0.050189, avg acc 0.983610, time taken 30.637084 secs\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCH):\n",
    "    last = time.time()\n",
    "    TOTAL_LOSS, ACCURACY = 0, 0\n",
    "    for n in range(0, (mnist.train.images.shape[0] // BATCH_SIZE) * BATCH_SIZE, BATCH_SIZE):\n",
    "        batch_x = mnist.train.images[n: n + BATCH_SIZE, :].reshape((-1, 28, 28))\n",
    "        acc, cost, _ = sess.run([model.accuracy, model.cost, model.optimizer], \n",
    "                           feed_dict = {model.X : batch_x, \n",
    "                                         model.Y : mnist.train.labels[n: n + BATCH_SIZE, :]})\n",
    "        ACCURACY += acc\n",
    "        TOTAL_LOSS += cost\n",
    "    TOTAL_LOSS /= (mnist.train.images.shape[0] // BATCH_SIZE)\n",
    "    ACCURACY /= (mnist.train.images.shape[0] // BATCH_SIZE)\n",
    "    print('epoch %d, avg loss %f, avg acc %f, time taken %f secs'%(i+1,TOTAL_LOSS,ACCURACY,time.time()-last))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
