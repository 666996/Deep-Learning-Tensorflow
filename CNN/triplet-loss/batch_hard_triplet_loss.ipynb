{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train-images-idx3-ubyte.gz\n",
      "Extracting train-labels-idx1-ubyte.gz\n",
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = mnist.train._images.reshape((-1,28,28,1))\n",
    "train_Y =mnist.train._labels\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = mnist.test._images.reshape((-1,28,28,1))\n",
    "test_Y =mnist.test._labels\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pairwise_distances(embeddings, squared=False):\n",
    "    \"\"\"Compute the 2D matrix of distances between all the embeddings.\n",
    "    Args:\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "    Returns:\n",
    "        pairwise_distances: tensor of shape (batch_size, batch_size)\n",
    "    \"\"\"\n",
    "    # Get the dot product between all embeddings\n",
    "    # shape (batch_size, batch_size)\n",
    "    dot_product = tf.matmul(embeddings, tf.transpose(embeddings))\n",
    "\n",
    "    # Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.\n",
    "    # This also provides more numerical stability (the diagonal of the result will be exactly 0).\n",
    "    # shape (batch_size,)\n",
    "    square_norm = tf.diag_part(dot_product)\n",
    "\n",
    "    # Compute the pairwise distance matrix as we have:\n",
    "    # ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2\n",
    "    # shape (batch_size, batch_size)\n",
    "    distances = tf.expand_dims(square_norm, 1) - 2.0 * dot_product + tf.expand_dims(square_norm, 0)\n",
    "\n",
    "    # Because of computation errors, some distances might be negative so we put everything >= 0.0\n",
    "    distances = tf.maximum(distances, 0.0)\n",
    "\n",
    "    if not squared:\n",
    "        # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)\n",
    "        # we need to add a small epsilon where distances == 0.0\n",
    "        mask = tf.to_float(tf.equal(distances, 0.0))\n",
    "        distances = distances + mask * 1e-16\n",
    "\n",
    "        distances = tf.sqrt(distances)\n",
    "\n",
    "        # Correct the epsilon added: set the distances on the mask to be exactly 0.0\n",
    "        distances = distances * (1.0 - mask)\n",
    "\n",
    "    return distances\n",
    "\n",
    "\n",
    "def _get_anchor_positive_triplet_mask(labels):\n",
    "    \"\"\"Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    Returns:\n",
    "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\n",
    "    \"\"\"\n",
    "    # Check that i and j are distinct\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.logical_not(indices_equal)\n",
    "\n",
    "    # Check if labels[i] == labels[j]\n",
    "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\n",
    "    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "\n",
    "    # Combine the two masks\n",
    "    mask = tf.logical_and(indices_not_equal, labels_equal)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def _get_anchor_negative_triplet_mask(labels):\n",
    "    \"\"\"Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    Returns:\n",
    "        mask: tf.bool `Tensor` with shape [batch_size, batch_size]\n",
    "    \"\"\"\n",
    "    # Check if labels[i] != labels[k]\n",
    "    # Uses broadcasting where the 1st argument has shape (1, batch_size) and the 2nd (batch_size, 1)\n",
    "    labels_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "\n",
    "    mask = tf.logical_not(labels_equal)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def _get_triplet_mask(labels):\n",
    "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
    "    A triplet (i, j, k) is valid if:\n",
    "        - i, j, k are distinct\n",
    "        - labels[i] == labels[j] and labels[i] != labels[k]\n",
    "    Args:\n",
    "        labels: tf.int32 `Tensor` with shape [batch_size]\n",
    "    \"\"\"\n",
    "    # Check that i, j and k are distinct\n",
    "    indices_equal = tf.cast(tf.eye(tf.shape(labels)[0]), tf.bool)\n",
    "    indices_not_equal = tf.logical_not(indices_equal)\n",
    "    i_not_equal_j = tf.expand_dims(indices_not_equal, 2)\n",
    "    i_not_equal_k = tf.expand_dims(indices_not_equal, 1)\n",
    "    j_not_equal_k = tf.expand_dims(indices_not_equal, 0)\n",
    "\n",
    "    distinct_indices = tf.logical_and(tf.logical_and(i_not_equal_j, i_not_equal_k), j_not_equal_k)\n",
    "\n",
    "\n",
    "    # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
    "    label_equal = tf.equal(tf.expand_dims(labels, 0), tf.expand_dims(labels, 1))\n",
    "    i_equal_j = tf.expand_dims(label_equal, 2)\n",
    "    i_equal_k = tf.expand_dims(label_equal, 1)\n",
    "\n",
    "    valid_labels = tf.logical_and(i_equal_j, tf.logical_not(i_equal_k))\n",
    "\n",
    "    # Combine the two masks\n",
    "    mask = tf.logical_and(distinct_indices, valid_labels)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def batch_hard_triplet_loss(labels, embeddings, margin, squared=False):\n",
    "    \"\"\"Build the triplet loss over a batch of embeddings.\n",
    "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
    "    Args:\n",
    "        labels: labels of the batch, of size (batch_size,)\n",
    "        embeddings: tensor of shape (batch_size, embed_dim)\n",
    "        margin: margin for triplet loss\n",
    "        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.\n",
    "                 If false, output is the pairwise euclidean distance matrix.\n",
    "    Returns:\n",
    "        triplet_loss: scalar tensor containing the triplet loss\n",
    "    \"\"\"\n",
    "    # Get the pairwise distance matrix\n",
    "    pairwise_dist = _pairwise_distances(embeddings, squared=squared)\n",
    "\n",
    "    # For each anchor, get the hardest positive\n",
    "    # First, we need to get a mask for every valid positive (they should have same label)\n",
    "    mask_anchor_positive = _get_anchor_positive_triplet_mask(labels)\n",
    "    mask_anchor_positive = tf.to_float(mask_anchor_positive)\n",
    "\n",
    "    # We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))\n",
    "    anchor_positive_dist = tf.multiply(mask_anchor_positive, pairwise_dist)\n",
    "\n",
    "    # shape (batch_size, 1)\n",
    "    hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=1, keepdims=True)\n",
    "    tf.summary.scalar(\"hardest_positive_dist\", tf.reduce_mean(hardest_positive_dist))\n",
    "\n",
    "    # For each anchor, get the hardest negative\n",
    "    # First, we need to get a mask for every valid negative (they should have different labels)\n",
    "    mask_anchor_negative = _get_anchor_negative_triplet_mask(labels)\n",
    "    mask_anchor_negative = tf.to_float(mask_anchor_negative)\n",
    "\n",
    "    # We add the maximum value in each row to the invalid negatives (label(a) == label(n))\n",
    "    max_anchor_negative_dist = tf.reduce_max(pairwise_dist, axis=1, keepdims=True)\n",
    "    anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (1.0 - mask_anchor_negative)\n",
    "\n",
    "    # shape (batch_size,)\n",
    "    hardest_negative_dist = tf.reduce_min(anchor_negative_dist, axis=1, keepdims=True)\n",
    "    tf.summary.scalar(\"hardest_negative_dist\", tf.reduce_mean(hardest_negative_dist))\n",
    "\n",
    "    # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "    triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + margin, 0.0)\n",
    "\n",
    "    # Get final mean triplet loss\n",
    "    triplet_loss = tf.reduce_mean(triplet_loss)\n",
    "\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutionize(x, conv_w, h = 1):\n",
    "    return tf.nn.conv2d(input = x, filter = conv_w, strides = [1, h, h, 1], padding = 'SAME')\n",
    "\n",
    "def pooling(wx):\n",
    "    return tf.nn.max_pool(wx, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "\n",
    "def create_network(X, scope='conv',reuse=False):\n",
    "    with tf.variable_scope(scope,reuse=reuse):\n",
    "        w1 = tf.Variable(tf.random_normal([3, 3, 1, 2], stddev = 0.5))\n",
    "        b1 = tf.Variable(tf.zeros(shape = [2]))\n",
    "        w2 = tf.Variable(tf.random_normal([3, 3, 2, 4], stddev = 0.5))\n",
    "        b2 = tf.Variable(tf.zeros(shape = [4]))\n",
    "        w3 = tf.Variable(tf.random_normal([3, 3, 4, 8], stddev = 0.5))\n",
    "        b3 = tf.Variable(tf.zeros(shape = [8]))\n",
    "        w4 = tf.Variable(tf.random_normal([128, 2], stddev = 0.5))\n",
    "        b4 = tf.Variable(tf.zeros(shape = [2]))\n",
    "\n",
    "        conv1 = pooling(tf.nn.relu(convolutionize(X, w1) + b1))\n",
    "        conv2 = pooling(tf.nn.relu(convolutionize(conv1, w2) + b2))\n",
    "        conv3 = pooling(tf.nn.relu(convolutionize(conv2, w3) + b3))\n",
    "        conv3 = tf.reshape(conv3, [-1, 128])\n",
    "        return tf.matmul(conv3, w4) + b4\n",
    "    \n",
    "class Siamese:\n",
    "    def __init__(self):\n",
    "        self.X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "        self.Y = tf.placeholder(tf.int64,[None])\n",
    "        \n",
    "        self.embedded = create_network(self.X)\n",
    "        \n",
    "        self.cost = batch_hard_triplet_loss(self.Y, self.embedded, margin=0.5, squared=False)\n",
    "        self.optimizer = tf.train.AdamOptimizer(1e-3).minimize(self.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "model = Siamese()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, avg loss: 3.752330\n",
      "epoch: 2, avg loss: 0.532185\n",
      "epoch: 3, avg loss: 0.500686\n",
      "epoch: 4, avg loss: 0.500270\n",
      "epoch: 5, avg loss: 0.500138\n",
      "epoch: 6, avg loss: 0.500087\n",
      "epoch: 7, avg loss: 0.500060\n",
      "epoch: 8, avg loss: 0.500040\n",
      "epoch: 9, avg loss: 0.500024\n",
      "epoch: 10, avg loss: 0.500017\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCH = 10\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    total_loss = 0\n",
    "    for k in range(0, (len(train_X)//BATCH_SIZE)*BATCH_SIZE, BATCH_SIZE):\n",
    "        loss, _ = sess.run([model.cost,model.optimizer],feed_dict={model.X:train_X[k:k+BATCH_SIZE],\n",
    "                                                                  model.Y:train_Y[k:k+BATCH_SIZE]})\n",
    "        total_loss += loss\n",
    "    total_loss /= (len(train_X)//BATCH_SIZE)\n",
    "    print('epoch: %d, avg loss: %f'%(i+1,total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.embedded.eval({model.X: test_X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from matplotlib import offsetbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_base.py:2917: UserWarning: Attempting to set identical left==right results\n",
      "in singular transformations; automatically expanding.\n",
      "left=0.052260652, right=0.052260652\n",
      "  'left=%s, right=%s') % (left, right))\n",
      "/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_base.py:3193: UserWarning: Attempting to set identical bottom==top results\n",
      "in singular transformations; automatically expanding.\n",
      "bottom=0.01155778, top=0.01155778\n",
      "  'bottom=%s, top=%s') % (bottom, top))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb03bff0940>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test = mnist.test.images.reshape([-1, 28, 28])\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "ax_min = np.min(embed,0)\n",
    "ax_max = np.max(embed,0)\n",
    "ax_dist_sq = np.sum((ax_max-ax_min)**2)\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(111)\n",
    "colormap = plt.get_cmap('tab10')\n",
    "shown_images = np.array([[1., 1.]])\n",
    "for i in range(embed.shape[0]):\n",
    "    dist = np.sum((embed[i] - shown_images)**2, 1)\n",
    "    if np.min(dist) < 3e-4*ax_dist_sq:\n",
    "        continue\n",
    "    shown_images = np.r_[shown_images, [embed[i]]]\n",
    "    patch_to_color = np.expand_dims(x_test[i], -1)\n",
    "    patch_to_color = np.tile(patch_to_color, (1, 1, 3))\n",
    "    patch_to_color = (1-patch_to_color) * (1,1,1) + patch_to_color * colormap(y_test[i]/10.)[:3]\n",
    "    imagebox = offsetbox.AnnotationBbox(\n",
    "        offsetbox.OffsetImage(patch_to_color, zoom=0.5, cmap=plt.cm.gray_r),\n",
    "        xy=embed[i], frameon=False\n",
    "    )\n",
    "    ax.add_artist(imagebox)\n",
    "\n",
    "plt.axis([ax_min[0], ax_max[0], ax_min[1], ax_max[1]])\n",
    "plt.title('Embedding from the last layer of the network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
