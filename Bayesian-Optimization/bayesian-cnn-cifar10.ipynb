{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please use Python 2. Python 3 got Cpickle problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = cPickle.load(fo)\n",
    "    return dict\n",
    "\n",
    "def reshape_image(img):\n",
    "    img = img.reshape([3, 32, 32])\n",
    "    return img.transpose([1, 2, 0])\n",
    "\n",
    "unique_name = unpickle('/home/husein/space/cifar/cifar-10-batches-py/batches.meta')['label_names']\n",
    "cifar10 = unpickle('/home/husein/space/cifar/cifar-10-batches-py/data_batch_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = cifar10['data'][:300, :]\n",
    "y_data = cifar10['labels'][:300]\n",
    "onehot = np.zeros((x_data.shape[0], len(unique_name)))\n",
    "for i in range(x_data.shape[0]):\n",
    "    onehot[i, y_data[i]] = 1.0\n",
    "    \n",
    "x_train, x_test, y_train, y_test, y_train_label, y_test_label = train_test_split(x_data, onehot, y_data, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Activation function:\n",
    "0- for sigmoid\n",
    "1- for tanh\n",
    "2- for relu\n",
    "\n",
    "Now the constants are:\n",
    "1- batch size : 10\n",
    "2- epoch: 20\n",
    "3- adaptive gradient descent\n",
    "4- softmax with cross entropy\n",
    "5- 2 fully connected layers\n",
    "```\n",
    "\n",
    "So you can change anything you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_network(fully_conn_size, len_layer_conv, kernel_size, learning_rate, pooling_size, multiply,\n",
    "                   dropout_rate, beta, activation, batch_normalization, batch_size = 10):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    if activation == 0:\n",
    "        activation = tf.nn.sigmoid\n",
    "    elif activation == 1:\n",
    "        activation = tf.nn.tanh\n",
    "    else:\n",
    "        activation = tf.nn.relu\n",
    "    \n",
    "    def conv_layer(x, conv, out_shape):\n",
    "        w = tf.Variable(tf.truncated_normal([conv, conv, int(x.shape[3]), out_shape]))\n",
    "        b = tf.Variable(tf.truncated_normal([out_shape], stddev = 0.01))\n",
    "        return tf.nn.conv2d(x, w, [1, 1, 1, 1], padding = 'SAME') + b\n",
    "    \n",
    "    def fully_connected(x, out_shape):\n",
    "        w = tf.Variable(tf.truncated_normal([int(x.shape[1]), out_shape]))\n",
    "        b = tf.Variable(tf.truncated_normal([out_shape], stddev = 0.01))\n",
    "        return tf.matmul(x, w) + b\n",
    "    \n",
    "    def pooling(x, k = 2, stride = 2):\n",
    "        return tf.nn.max_pool(x, ksize = [1, k, k, 1], strides = [1, stride, stride, 1], padding = 'SAME')\n",
    "        \n",
    "    X = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "    Y = tf.placeholder(tf.float32, (None, len(unique_name)))\n",
    "    train = tf.placeholder(tf.bool)\n",
    "    for i in range(len_layer_conv):\n",
    "        if i == 0:\n",
    "            conv = activation(conv_layer(X, kernel_size, int(np.around(int(X.shape[3]) * multiply))))\n",
    "        else:\n",
    "            conv = activation(conv_layer(conv, kernel_size, int(np.around(int(conv.shape[3]) * multiply))))\n",
    "        conv = pooling(conv, k = pooling_size, stride = pooling_size)\n",
    "        if batch_normalization:\n",
    "            conv = tf.layers.batch_normalization(conv, training = train)\n",
    "        conv = tf.nn.dropout(conv, dropout_rate)\n",
    "    print(conv.shape)\n",
    "    output_shape = int(conv.shape[1]) * int(conv.shape[2]) * int(conv.shape[3])\n",
    "    conv = tf.reshape(conv, [-1, output_shape])\n",
    "    for i in range(2):\n",
    "        if i == 0:\n",
    "            fc = activation(fully_connected(conv, fully_conn_size))\n",
    "        else:\n",
    "            fc = activation(fully_connected(fc, fully_conn_size))\n",
    "        fc = tf.nn.dropout(fc, dropout_rate)\n",
    "        if batch_normalization:\n",
    "            fc = tf.layers.batch_normalization(fc, training = train)\n",
    "    logits = fully_connected(fc, len(unique_name))\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = Y, logits = logits))\n",
    "    cost += sum(beta * tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    COST, TEST_COST, ACC, TEST_ACC = [], [], [], []\n",
    "    for i in range(20):\n",
    "        train_acc, train_loss = 0, 0\n",
    "        for n in range(0, (x_train.shape[0] // batch_size) * batch_size, batch_size):\n",
    "            batch_x = np.zeros((batch_size, 32, 32, 3))\n",
    "            for k in range(batch_size):\n",
    "                batch_x[k, :, :, :] = reshape_image(x_train[n + k, :])\n",
    "            _, loss = sess.run([optimizer, cost], feed_dict = {X: batch_x, Y: y_train[n: n + batch_size, :], train: True})\n",
    "            train_acc += sess.run(accuracy, feed_dict = {X: batch_x, Y: y_train[n: n + batch_size, :], train: False})\n",
    "            train_loss += loss\n",
    "        batch_x = np.zeros((x_test.shape[0], 32, 32, 3))\n",
    "        for k in range(x_test.shape[0]):\n",
    "            batch_x[k, :, :, :] = reshape_image(x_test[k, :])\n",
    "        results = sess.run([cost, accuracy], feed_dict = {X: batch_x, Y: y_test, train: False})\n",
    "        TEST_COST.append(results[0])\n",
    "        TEST_ACC.append(results[1])\n",
    "        train_loss /= (x_train.shape[0] // batch_size)\n",
    "        train_acc /= (x_train.shape[0] // batch_size)\n",
    "        ACC.append(train_acc)\n",
    "        COST.append(train_loss)\n",
    "    COST = np.array(COST).mean()\n",
    "    TEST_COST = np.array(TEST_COST).mean()\n",
    "    ACC = np.array(ACC).mean()\n",
    "    TEST_ACC = np.array(TEST_ACC).mean()\n",
    "    return COST, TEST_COST, ACC, TEST_ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_nn(fully_conn_size, len_layer_conv, kernel_size, learning_rate, pooling_size, multiply,\n",
    "                dropout_rate, beta, activation, batch_normalization):\n",
    "    global accbest\n",
    "    param = {\n",
    "        'fully_conn_size' : int(np.around(fully_conn_size)),\n",
    "        'len_layer_conv' : int(np.around(len_layer_conv)),\n",
    "        'kernel_size': int(np.around(kernel_size)),\n",
    "        'learning_rate' : max(min(learning_rate, 1), 0.0001),\n",
    "        'pooling_size': int(np.around(pooling_size)),\n",
    "        'multiply': multiply,\n",
    "        'dropout_rate' : max(min(dropout_rate, 0.99), 0),\n",
    "        'beta' : max(min(beta, 0.5), 0.000001),\n",
    "        'activation': int(np.around(activation)),\n",
    "        'batch_normalization' : int(np.around(batch_normalization))\n",
    "    }\n",
    "    learning_cost, valid_cost, learning_acc, valid_acc = neural_network(**param)\n",
    "    print(\"stop after 20 iteration with train cost %f, valid cost %f, train acc %f, valid acc %f\" % (learning_cost, valid_cost, learning_acc, valid_acc))\n",
    "    if (valid_acc > accbest):\n",
    "        costbest = valid_acc\n",
    "    return valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   activation |   batch_normalization |      beta |   dropout_rate |   fully_conn_size |   kernel_size |   learning_rate |   len_layer_conv |   multiply |   pooling_size | \n",
      "(?, 1, 1, 100)\n",
      "stop after 20 iteration with train cost 2008170.116490, valid cost 486246.000000, train acc 0.151042, valid acc 0.133333\n",
      "    1 | 00m06s | \u001b[35m   0.13333\u001b[0m | \u001b[32m      1.4565\u001b[0m | \u001b[32m               0.8903\u001b[0m | \u001b[32m   0.2951\u001b[0m | \u001b[32m        0.5427\u001b[0m | \u001b[32m          61.9462\u001b[0m | \u001b[32m       4.0407\u001b[0m | \u001b[32m         0.1692\u001b[0m | \u001b[32m          4.7475\u001b[0m | \u001b[32m    2.0314\u001b[0m | \u001b[32m        3.4064\u001b[0m | \n",
      "(?, 1, 1, 40)\n",
      "stop after 20 iteration with train cost 359.077862, valid cost 41.487034, train acc 0.200417, valid acc 0.131667\n",
      "    2 | 00m02s |    0.13167 |       1.0275 |                0.4410 |    0.1257 |         0.6587 |           59.6901 |        3.0467 |          0.6025 |           3.9315 |     1.9162 |         3.0427 | \n",
      "(?, 2, 2, 16)\n",
      "stop after 20 iteration with train cost 330.979133, valid cost 9.589639, train acc 0.198333, valid acc 0.133333\n",
      "    3 | 00m04s |    0.13333 |       0.4947 |                0.6139 |    0.3523 |         0.7974 |           94.9314 |        5.8448 |          0.3150 |           3.3750 |     1.7794 |         2.9960 | \n",
      "(?, 2, 2, 168)\n",
      "stop after 20 iteration with train cost 571.771640, valid cost 4.475763, train acc 0.217292, valid acc 0.133333\n",
      "    4 | 00m02s |    0.13333 |       1.1266 |                0.0823 |    0.3143 |         0.4237 |           30.2263 |        2.8229 |          0.4735 |           3.8008 |     2.7505 |         2.1838 | \n",
      "(?, 2, 2, 237)\n",
      "stop after 20 iteration with train cost nan, valid cost nan, train acc 0.148125, valid acc 0.133333\n",
      "    5 | 00m02s |    0.13333 |       1.5303 |                0.1720 |    0.0419 |         0.2041 |           58.8475 |        3.1729 |          0.3426 |           4.0076 |     2.9666 |         2.0881 | \n",
      "(?, 1, 1, 73)\n",
      "stop after 20 iteration with train cost 13302.843301, valid cost 2.315546, train acc 0.244792, valid acc 0.133333\n",
      "    6 | 00m05s |    0.13333 |       0.8586 |                0.8299 |    0.3653 |         0.3140 |          104.6627 |        5.9643 |          0.9526 |           3.7000 |     2.2140 |         3.4398 | \n",
      "(?, 4, 4, 56)\n",
      "stop after 20 iteration with train cost nan, valid cost nan, train acc 0.083542, valid acc 0.050000\n",
      "    7 | 00m02s |    0.05000 |       1.9712 |                0.3703 |    0.4468 |         0.7693 |           27.9524 |        3.8054 |          0.5529 |           3.0131 |     2.6585 |         2.1260 | \n",
      "(?, 2, 2, 7)\n",
      "stop after 20 iteration with train cost 2070.000343, valid cost 11.033470, train acc 0.220000, valid acc 0.133333\n",
      "    8 | 00m05s |    0.13333 |       1.2985 |                0.8392 |    0.2644 |         0.3082 |          125.7212 |        2.4825 |          0.5585 |           3.6307 |     1.1996 |         2.1053 | \n",
      "(?, 1, 1, 184)\n",
      "stop after 20 iteration with train cost 821.436800, valid cost 62.800335, train acc 0.200417, valid acc 0.129167\n",
      "    9 | 00m02s |    0.12917 |       1.1918 |                0.3009 |    0.2188 |         0.4814 |          100.3948 |        2.5854 |          0.3794 |           3.9951 |     2.8247 |         3.1268 | \n",
      "(?, 2, 2, 27)\n",
      "stop after 20 iteration with train cost nan, valid cost nan, train acc 0.083333, valid acc 0.050000\n",
      "   10 | 00m01s |    0.05000 |       1.6808 |                0.3121 |    0.3826 |         0.6200 |           99.0217 |        2.6936 |          0.8531 |           3.4801 |     2.0875 |         2.7903 | \n",
      "(?, 1, 1, 237)\n",
      "stop after 20 iteration with train cost 101.862314, valid cost 20.170437, train acc 0.202083, valid acc 0.130000\n",
      "   11 | 00m02s |    0.13000 |       0.0386 |                0.2792 |    0.1298 |         0.2041 |           56.0794 |        2.1811 |          0.4325 |           3.7931 |     2.9668 |         3.4967 | \n",
      "(?, 1, 1, 12)\n",
      "stop after 20 iteration with train cost 32.727261, valid cost 3.304677, train acc 0.200625, valid acc 0.133333\n",
      "   12 | 00m05s |    0.13333 |       0.0957 |                0.9127 |    0.3811 |         0.7214 |          100.4090 |        4.2859 |          0.2571 |           4.9440 |     1.3391 |         3.7319 | \n",
      "(?, 1, 1, 182)\n",
      "stop after 20 iteration with train cost nan, valid cost nan, train acc 0.083542, valid acc 0.050000\n",
      "   13 | 00m03s |    0.05000 |       1.6693 |                0.1889 |    0.1313 |         0.2157 |           54.9208 |        4.0497 |          0.3237 |           4.8071 |     2.2457 |         2.3954 | \n",
      "(?, 2, 2, 164)\n",
      "stop after 20 iteration with train cost 111.949912, valid cost 84.082855, train acc 0.216042, valid acc 0.129167\n",
      "   14 | 00m02s |    0.12917 |       0.2117 |                0.2318 |    0.0171 |         0.7501 |           96.0475 |        2.8243 |          0.6559 |           4.3425 |     2.7253 |         2.1887 | \n",
      "(?, 1, 1, 9)\n",
      "stop after 20 iteration with train cost 7.330570, valid cost 2.319196, train acc 0.258125, valid acc 0.133333\n",
      "   15 | 00m04s |    0.13333 |       1.8424 |                0.5583 |    0.4786 |         0.1465 |           55.4223 |        2.8651 |          0.9967 |           3.2202 |     1.4879 |         3.6654 | \n",
      "(?, 1, 1, 18)\n",
      "stop after 20 iteration with train cost nan, valid cost nan, train acc 0.083750, valid acc 0.050000\n",
      "   16 | 00m02s |    0.05000 |       1.6451 |                0.1834 |    0.4319 |         0.4315 |          113.7749 |        4.6080 |          0.6933 |           3.7359 |     1.5416 |         3.0782 | \n",
      "(?, 1, 1, 126)\n",
      "stop after 20 iteration with train cost 198.105689, valid cost 4.173694, train acc 0.201458, valid acc 0.131667\n",
      "   17 | 00m02s |    0.13167 |       1.2770 |                0.4776 |    0.4513 |         0.2476 |          100.0807 |        2.3012 |          0.3148 |           3.9662 |     2.5190 |         3.4889 | \n",
      "(?, 1, 1, 236)\n",
      "stop after 20 iteration with train cost 566.766217, valid cost 15.120625, train acc 0.201250, valid acc 0.134167\n",
      "   18 | 00m02s | \u001b[35m   0.13417\u001b[0m | \u001b[32m      1.1439\u001b[0m | \u001b[32m               0.1005\u001b[0m | \u001b[32m   0.3424\u001b[0m | \u001b[32m        0.8912\u001b[0m | \u001b[32m         114.8697\u001b[0m | \u001b[32m       3.1598\u001b[0m | \u001b[32m         0.3192\u001b[0m | \u001b[32m          3.6584\u001b[0m | \u001b[32m    2.9492\u001b[0m | \u001b[32m        3.7208\u001b[0m | \n",
      "(?, 1, 1, 3)\n",
      "stop after 20 iteration with train cost 10.717329, valid cost 2.350919, train acc 0.220417, valid acc 0.133333\n",
      "   19 | 00m05s |    0.13333 |       0.0145 |                0.5464 |    0.1622 |         0.6554 |          100.6420 |        5.4176 |          0.8350 |           3.5967 |     1.1097 |         3.5063 | \n",
      "(?, 1, 1, 103)\n",
      "stop after 20 iteration with train cost 149.477733, valid cost 3.264791, train acc 0.245833, valid acc 0.133333\n",
      "   20 | 00m02s |    0.13333 |       0.4013 |                0.3964 |    0.3400 |         0.9426 |           22.3087 |        5.1583 |          0.3912 |           4.0846 |     2.4608 |         2.7389 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   activation |   batch_normalization |      beta |   dropout_rate |   fully_conn_size |   kernel_size |   learning_rate |   len_layer_conv |   multiply |   pooling_size | \n",
      "(?, 1, 1, 3)\n",
      "stop after 20 iteration with train cost 2.818659, valid cost 2.717047, train acc 0.168125, valid acc 0.125833\n",
      "   21 | 01m13s |    0.12583 |       0.0000 |                0.0000 |    0.0000 |         0.1000 |           16.0000 |        2.0000 |          1.0000 |           5.0000 |     1.0000 |         4.0000 | \n",
      "(?, 1, 1, 81)\n",
      "stop after 20 iteration with train cost 25.373671, valid cost 24.730690, train acc 0.106250, valid acc 0.110000\n",
      "   22 | 00m35s |    0.11000 |       0.0000 |                0.0000 |    0.0000 |         0.1000 |           76.1813 |        2.0000 |          0.0001 |           3.0000 |     3.0000 |         4.0000 | \n",
      "(?, 1, 1, 81)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop after 20 iteration with train cost 32.782606, valid cost 32.204044, train acc 0.101875, valid acc 0.097500\n",
      "   23 | 00m35s |    0.09750 |       0.0000 |                0.0000 |    0.0000 |         0.1000 |          128.0000 |        7.0000 |          0.0001 |           3.0000 |     3.0000 |         4.0000 | \n",
      "(?, 1, 1, 81)\n",
      "stop after 20 iteration with train cost 9.998409, valid cost 30.124105, train acc 0.103125, valid acc 0.090000\n",
      "   24 | 00m39s |    0.09000 |       0.0000 |                1.0000 |    0.0000 |         0.1000 |           97.2206 |        7.0000 |          0.0001 |           3.0000 |     3.0000 |         4.0000 | \n",
      "(?, 1, 1, 81)\n",
      "stop after 20 iteration with train cost 5719.770920, valid cost 5713.321777, train acc 0.106250, valid acc 0.088333\n",
      "   25 | 00m40s |    0.08833 |       0.0000 |                0.0000 |    0.4900 |         0.1000 |          106.6973 |        2.0000 |          0.0001 |           3.0000 |     3.0000 |         4.0000 | \n",
      "(?, 1, 1, 3)\n",
      "stop after 20 iteration with train cost 2026.791490, valid cost 2024.371338, train acc 0.104583, valid acc 0.101667\n",
      "   26 | 00m39s |    0.10167 |       0.0000 |                0.0000 |    0.4900 |         0.1000 |           86.3271 |        7.0000 |          0.0001 |           5.0000 |     1.0000 |         2.0000 | \n",
      "(?, 1, 1, 729)\n",
      "stop after 20 iteration with train cost nan, valid cost nan, train acc 0.183542, valid acc 0.133333\n",
      "   27 | 00m40s |    0.13333 |       2.0000 |                0.0000 |    0.0000 |         0.9900 |          122.8743 |        2.0000 |          1.0000 |           5.0000 |     3.0000 |         4.0000 | \n",
      "(?, 1, 1, 729)\n",
      "stop after 20 iteration with train cost 484.075631, valid cost 2.319522, train acc 0.261667, valid acc 0.133333\n",
      "   28 | 00m44s |    0.13333 |       0.0000 |                1.0000 |    0.4900 |         0.1000 |           38.3927 |        2.0000 |          1.0000 |           5.0000 |     3.0000 |         4.0000 | \n",
      "(?, 1, 1, 729)\n",
      "stop after 20 iteration with train cost 161934.436914, valid cost 161735.515625, train acc 0.098542, valid acc 0.090833\n",
      "   29 | 00m40s |    0.09083 |       0.0000 |                0.0000 |    0.4900 |         0.1000 |           91.1139 |        2.0000 |          0.0001 |           5.0000 |     3.0000 |         4.0000 | \n",
      "(?, 4, 4, 81)\n",
      "stop after 20 iteration with train cost 19011.979427, valid cost 3125141504.000000, train acc 0.101667, valid acc 0.095000\n",
      "   30 | 00m43s |    0.09500 |       2.0000 |                1.0000 |    0.4900 |         0.1000 |           67.0943 |        2.0000 |          0.0001 |           3.0000 |     3.0000 |         2.0000 | \n",
      "(?, 1, 1, 81)\n",
      "stop after 20 iteration with train cost 94.321815, valid cost 22.718958, train acc 0.191042, valid acc 0.118333\n",
      "   31 | 00m42s |    0.11833 |       0.0000 |                0.0000 |    0.4900 |         0.1000 |           64.4711 |        7.0000 |          1.0000 |           3.0000 |     3.0000 |         4.0000 | \n",
      "(?, 1, 1, 729)\n",
      "stop after 20 iteration with train cost 12.932306, valid cost 13.331874, train acc 0.095000, valid acc 0.091667\n",
      "   32 | 00m42s |    0.09167 |       0.0000 |                0.0000 |    0.0000 |         0.1000 |           26.9175 |        2.0000 |          0.0001 |           5.0000 |     3.0000 |         4.0000 | \n",
      "(?, 1, 1, 729)\n",
      "stop after 20 iteration with train cost 1810420.614583, valid cost 1808203.375000, train acc 0.100833, valid acc 0.110000\n",
      "   33 | 01m07s |    0.11000 |       0.0000 |                0.0000 |    0.4900 |         0.1000 |           16.0000 |        7.0000 |          0.0001 |           5.0000 |     3.0000 |         2.0000 | \n",
      "(?, 1, 1, 3)\n",
      "stop after 20 iteration with train cost 4.182123, valid cost 3.660193, train acc 0.163333, valid acc 0.126667\n",
      "   34 | 00m44s |    0.12667 |       0.0000 |                0.0000 |    0.0000 |         0.1000 |           32.3153 |        7.0000 |          1.0000 |           5.0000 |     1.0000 |         2.0000 | \n",
      "(?, 4, 4, 3)\n",
      "stop after 20 iteration with train cost 4.835538, valid cost 2.605304, train acc 0.274792, valid acc 0.133333\n",
      "   35 | 00m43s |    0.13333 |       0.0000 |                0.0000 |    0.4900 |         0.9900 |           34.5035 |        2.0000 |          1.0000 |           3.0000 |     1.0000 |         2.0000 | \n",
      "(?, 4, 4, 81)\n",
      "stop after 20 iteration with train cost 33747.258602, valid cost 33724.734375, train acc 0.107917, valid acc 0.098333\n",
      "   36 | 00m47s |    0.09833 |       0.0000 |                1.0000 |    0.4900 |         0.1000 |          121.3749 |        2.0000 |          0.0001 |           3.0000 |     3.0000 |         2.0000 | \n",
      "(?, 1, 1, 729)\n",
      "stop after 20 iteration with train cost 455.433505, valid cost 11.401892, train acc 0.181667, valid acc 0.111667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -2.71350418e-05]), 'nit': 4, 'funcalls': 47}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   37 | 00m46s |    0.11167 |       0.0000 |                0.0000 |    0.4900 |         0.1000 |           33.0480 |        2.0000 |          1.0000 |           5.0000 |     3.0000 |         2.0000 | \n",
      "(?, 1, 1, 81)\n",
      "stop after 20 iteration with train cost nan, valid cost nan, train acc 0.096250, valid acc 0.066667\n",
      "   38 | 00m45s |    0.06667 |       2.0000 |                0.0000 |    0.0000 |         0.1000 |           39.2425 |        2.0000 |          0.0001 |           3.0000 |     3.0000 |         4.0000 | \n",
      "(?, 1, 1, 3)\n",
      "stop after 20 iteration with train cost 8.769759, valid cost 5.812512, train acc 0.078958, valid acc 0.115833\n",
      "   39 | 00m46s |    0.11583 |       0.0000 |                1.0000 |    0.0000 |         0.9900 |           32.0688 |        3.5489 |          0.0001 |           3.0000 |     1.0000 |         4.0000 | \n",
      "(?, 1, 1, 3)\n",
      "stop after 20 iteration with train cost 3.545781, valid cost 3.373584, train acc 0.082500, valid acc 0.115000\n",
      "   40 | 00m44s |    0.11500 |       0.0000 |                0.0000 |    0.0000 |         0.9900 |           20.7268 |        4.5839 |          0.0001 |           5.0000 |     1.0000 |         2.0000 | \n",
      "(?, 1, 1, 729)\n",
      "stop after 20 iteration with train cost 163574.322917, valid cost 163374.781250, train acc 0.090625, valid acc 0.091667\n",
      "   41 | 00m46s |    0.09167 |       0.0000 |                0.0000 |    0.4900 |         0.1000 |          100.7270 |        2.0000 |          0.0001 |           5.0000 |     3.0000 |         4.0000 | \n",
      "(?, 4, 4, 3)\n",
      "stop after 20 iteration with train cost 12.494074, valid cost 5.014549, train acc 0.105208, valid acc 0.139167\n",
      "   42 | 00m46s | \u001b[35m   0.13917\u001b[0m | \u001b[32m      0.0000\u001b[0m | \u001b[32m               1.0000\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m        0.9900\u001b[0m | \u001b[32m          91.8885\u001b[0m | \u001b[32m       3.8067\u001b[0m | \u001b[32m         0.0001\u001b[0m | \u001b[32m          3.0000\u001b[0m | \u001b[32m    1.0000\u001b[0m | \u001b[32m        2.0000\u001b[0m | \n",
      "(?, 1, 1, 81)\n",
      "stop after 20 iteration with train cost 14.831696, valid cost 4481962.000000, train acc 0.084167, valid acc 0.050833\n",
      "   43 | 00m46s |    0.05083 |       2.0000 |                1.0000 |    0.0000 |         0.9900 |          128.0000 |        2.0000 |          0.0001 |           3.0000 |     3.0000 |         4.0000 | \n",
      "(?, 1, 1, 81)\n",
      "stop after 20 iteration with train cost 8.730399, valid cost 4077280512.000000, train acc 0.094583, valid acc 0.104167\n",
      "   44 | 00m46s |    0.10417 |       2.0000 |                1.0000 |    0.0000 |         0.1000 |          103.2247 |        2.0837 |          0.0001 |           3.0000 |     3.0000 |         4.0000 | \n",
      "(?, 4, 4, 81)\n",
      "stop after 20 iteration with train cost 33514.741565, valid cost 33492.203125, train acc 0.101667, valid acc 0.095833\n",
      "   45 | 00m43s |    0.09583 |       0.0000 |                1.0000 |    0.4900 |         0.1000 |          101.3569 |        4.2432 |          0.0001 |           3.0240 |     3.0000 |         2.0000 | \n",
      "(?, 1, 1, 729)\n",
      "stop after 20 iteration with train cost 14.724192, valid cost 20010471424.000000, train acc 0.106875, valid acc 0.164167\n",
      "   46 | 01m12s | \u001b[35m   0.16417\u001b[0m | \u001b[32m      2.0000\u001b[0m | \u001b[32m               1.0000\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m        0.9900\u001b[0m | \u001b[32m          75.2335\u001b[0m | \u001b[32m       7.0000\u001b[0m | \u001b[32m         0.0001\u001b[0m | \u001b[32m          5.0000\u001b[0m | \u001b[32m    3.0000\u001b[0m | \u001b[32m        4.0000\u001b[0m | \n",
      "(?, 1, 1, 3)\n",
      "stop after 20 iteration with train cost 8.570062, valid cost 7.071836, train acc 0.219792, valid acc 0.121667\n",
      "   47 | 00m44s |    0.12167 |       0.0000 |                0.0000 |    0.0000 |         0.9900 |          128.0000 |        2.0000 |          1.0000 |           5.0000 |     1.0000 |         2.0000 | \n",
      "(?, 1, 1, 81)\n",
      "stop after 20 iteration with train cost 8768.209446, valid cost 2.319522, train acc 0.262292, valid acc 0.133333\n",
      "   48 | 00m47s |    0.13333 |       0.0000 |                1.0000 |    0.4900 |         0.9900 |           42.8165 |        7.0000 |          1.0000 |           3.0000 |     3.0000 |         4.0000 | \n",
      "(?, 1, 1, 3)\n",
      "stop after 20 iteration with train cost 15.033110, valid cost 3.558356, train acc 0.260833, valid acc 0.116667\n",
      "   49 | 00m45s |    0.11667 |       0.0000 |                0.0000 |    0.4900 |         0.9900 |          122.0387 |        7.0000 |          1.0000 |           3.0000 |     1.0000 |         4.0000 | \n",
      "(?, 1, 1, 729)\n",
      "stop after 20 iteration with train cost 16.263203, valid cost 8.534091, train acc 0.091250, valid acc 0.068333\n",
      "   50 | 01m06s |    0.06833 |       0.0000 |                1.0000 |    0.0000 |         0.9900 |           92.1810 |        5.6116 |          0.0001 |           5.0000 |     3.0000 |         2.0000 | \n",
      "(?, 1, 1, 3)\n",
      "stop after 20 iteration with train cost 1606.707641, valid cost 1605.977905, train acc 0.095208, valid acc 0.072500\n",
      "   51 | 00m46s |    0.07250 |       0.0000 |                0.0000 |    0.4900 |         0.1000 |           76.8088 |        7.0000 |          0.0001 |           3.0000 |     1.0000 |         4.0000 | \n",
      "(?, 4, 4, 81)\n",
      "stop after 20 iteration with train cost 2.460649, valid cost 2.379506, train acc 0.203958, valid acc 0.135833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -3.24209129e-05]), 'nit': 3, 'funcalls': 55}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   52 | 00m48s |    0.13583 |       0.0000 |                1.0000 |    0.0000 |         0.9900 |           16.0000 |        2.0000 |          1.0000 |           3.0000 |     3.0000 |         2.0000 | \n",
      "(?, 1, 1, 3)\n",
      "stop after 20 iteration with train cost 3.341574, valid cost 29347958784.000000, train acc 0.139792, valid acc 0.127500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -3.15959728e-05]), 'nit': 4, 'funcalls': 53}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   53 | 00m52s |    0.12750 |       2.0000 |                1.0000 |    0.0000 |         0.9900 |           78.5702 |        2.0000 |          1.0000 |           5.0000 |     1.0000 |         4.0000 | \n",
      "(?, 1, 1, 3)\n",
      "stop after 20 iteration with train cost 16.973149, valid cost 2.319522, train acc 0.262292, valid acc 0.133333\n",
      "   54 | 00m51s |    0.13333 |       2.0000 |                1.0000 |    0.4900 |         0.9900 |          128.0000 |        7.0000 |          1.0000 |           5.0000 |     1.0000 |         2.0000 | \n",
      "(?, 1, 1, 81)\n",
      "stop after 20 iteration with train cost 2.323403, valid cost 2552851456.000000, train acc 0.119583, valid acc 0.123333\n",
      "   55 | 00m50s |    0.12333 |       2.0000 |                1.0000 |    0.0000 |         0.9900 |           59.7197 |        2.0000 |          1.0000 |           3.0000 |     3.0000 |         4.0000 | \n",
      "(?, 1, 1, 3)\n",
      "stop after 20 iteration with train cost 3.903047, valid cost 2.319522, train acc 0.261875, valid acc 0.133333\n",
      "   56 | 00m51s |    0.13333 |       0.0000 |                1.0000 |    0.4900 |         0.1000 |           46.0005 |        2.0000 |          1.0000 |           3.0000 |     1.0000 |         4.0000 | \n",
      "(?, 1, 1, 3)\n",
      "stop after 20 iteration with train cost nan, valid cost nan, train acc 0.183542, valid acc 0.133333\n",
      "   57 | 00m50s |    0.13333 |       2.0000 |                0.0000 |    0.0000 |         0.1000 |           70.8739 |        7.0000 |          1.0000 |           5.0000 |     1.0000 |         2.0000 | \n",
      "(?, 1, 1, 81)\n",
      "stop after 20 iteration with train cost 2.474757, valid cost 2.377540, train acc 0.223958, valid acc 0.131667\n",
      "   58 | 00m51s |    0.13167 |       0.0000 |                0.0000 |    0.0000 |         0.9900 |           18.5245 |        7.0000 |          1.0000 |           3.0000 |     3.0000 |         4.0000 | \n",
      "(?, 1, 1, 3)\n",
      "stop after 20 iteration with train cost 5.571828, valid cost 5.417197, train acc 0.102500, valid acc 0.111667\n",
      "   59 | 00m51s |    0.11167 |       0.0000 |                0.0000 |    0.0000 |         0.9900 |          105.8432 |        7.0000 |          0.0001 |           3.0000 |     1.0000 |         4.0000 | \n",
      "(?, 4, 4, 81)\n",
      "stop after 20 iteration with train cost 30901.746834, valid cost 30873.255859, train acc 0.103333, valid acc 0.101667\n",
      "   60 | 00m55s |    0.10167 |       0.0000 |                1.0000 |    0.4900 |         0.1000 |           34.7228 |        7.0000 |          0.0001 |           3.0000 |     3.0000 |         2.0000 | \n"
     ]
    }
   ],
   "source": [
    "accbest = 0.0\n",
    "NN_BAYESIAN = BayesianOptimization(generate_nn, \n",
    "                              {'fully_conn_size': (16, 128),\n",
    "                               'len_layer_conv': (3, 5),\n",
    "                               'kernel_size': (2, 7),\n",
    "                               'learning_rate': (0.0001, 1),\n",
    "                               'pooling_size': (2, 4),\n",
    "                               'multiply': (1, 3),\n",
    "                               'dropout_rate': (0.1, 0.99),\n",
    "                               'beta': (0.000001, 0.49),\n",
    "                               'activation': (0, 2),\n",
    "                               'batch_normalization': (0, 1)\n",
    "                              })\n",
    "NN_BAYESIAN.maximize(init_points = 20, n_iter = 40, acq = 'ei', xi = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum NN accuracy value: 0.164167\n",
      "Best NN parameters: {'fully_conn_size': 75.233542680827611, 'len_layer_conv': 5.0, 'activation': 2.0, 'dropout_rate': 0.98999999999999999, 'batch_normalization': 1.0, 'beta': 9.9999999999999995e-07, 'pooling_size': 4.0, 'multiply': 3.0, 'learning_rate': 0.0001, 'kernel_size': 7.0}\n"
     ]
    }
   ],
   "source": [
    "print('Maximum NN accuracy value: %f' % NN_BAYESIAN.res['max']['max_val'])\n",
    "print('Best NN parameters: %s' % NN_BAYESIAN.res['max']['max_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
